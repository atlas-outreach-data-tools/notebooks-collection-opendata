{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"../../images/ATLASOD.gif\" style=\"width:50%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to rediscover the Higgs boson yourself!\n",
    "This notebook uses ATLAS Open Data http://opendata.atlas.cern to show you the steps to rediscover the Higgs boson yourself!\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 2 photons per event, so that processing is quicker.\n",
    "\n",
    "This analysis loosely follows the discovery of the Higgs boson by ATLAS https://arxiv.org/pdf/1207.7214.pdf (mostly Section 5 and 5.1)\n",
    "\n",
    "Feynman diagram pictures are borrowed from our friends at https://www.particlezoo.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"Hyy_feynman.png\" style=\"width:40%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time setup on your computer (no need on mybinder)\n",
    "This first cell only needs to be run the first time you open this notebook on your computer. \n",
    "\n",
    "If you close Jupyter and re-open on the same computer, you won't need to run this first cell again.\n",
    "\n",
    "If you open on binder, you don't need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --user pip # update the pip package installer\n",
    "!{sys.executable} -m pip install -U numpy pandas uproot matplotlib lmfit --user # install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To setup everytime\n",
    "Cell -> Run All Below\n",
    "\n",
    "to be done every time you re-open this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot # for reading .root files\n",
    "import pandas as pd # to store data as dataframe\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from lmfit.models import PolynomialModel, GaussianModel # for the signal and background fits\n",
    "from matplotlib.ticker import MaxNLocator,AutoMinorLocator # for minor ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General definitions of luminosity, fraction of data used, where to access the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "#lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "fraction = 0.8 # reduce this is you want the code to run quicker\n",
    "\n",
    "#tuple_path = \"Input/GamGam/Data/\" # local \n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/GamGam/Data/\" # web address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samples to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['data_A'] #'data_B','data_C','data_D' # add if you want more data\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to get data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    data = {} # define empty dictionary to hold all data\n",
    "    for s in samples: # loop over samples defined above\n",
    "        print('Processing '+s+' samples') # print which sample is being processed\n",
    "        frames = [] # define empty list to hold data\n",
    "        for val in samples[s]['list']: # loop over each file\n",
    "            fileString = tuple_path+val+\".GamGam.root\" # file name to open\n",
    "            if fileString != \"\": # if this file name has worked\n",
    "                temp = read_file(fileString,val) # call the function read_file defined below\n",
    "                frames.append(temp) # append dataframe returned from read_file to list of dataframes\n",
    "            else: # fileString == \"\"\n",
    "                print(\"Error: \"+val+\" not found!\") # print error message\n",
    "        data[s] = pd.concat(frames) # concatenate list of dataframes together into one dataframe\n",
    "    \n",
    "    return data # return dictionary of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate diphoton invariant mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_myy(photon_pt,photon_eta,photon_phi,photon_E):\n",
    "    # first photon is [0], 2nd photon is [1] etc\n",
    "    px_0 = photon_pt[0]*math.cos(photon_phi[0]) # x-component of photon[0] momentum\n",
    "    py_0 = photon_pt[0]*math.sin(photon_phi[0]) # y-component of photon[0] momentum\n",
    "    pz_0 = photon_pt[0]*math.sinh(photon_eta[0]) # z-component of photon[0] momentum\n",
    "    px_1 = photon_pt[1]*math.cos(photon_phi[1]) # x-component of photon[1] momentum\n",
    "    py_1 = photon_pt[1]*math.sin(photon_phi[1]) # y-component of photon[1] momentum\n",
    "    pz_1 = photon_pt[1]*math.sinh(photon_eta[1]) # z-component of photon[1] momentum\n",
    "    sumpx = px_0 + px_1 # x-component of diphoton momentum\n",
    "    sumpy = py_0 + py_1 # y-component of diphoton momentum\n",
    "    sumpz = pz_0 + pz_1 # z-component of diphoton momentum \n",
    "    sump = math.sqrt(sumpx**2 + sumpy**2 + sumpz**2) # magnitude of diphoton momentum \n",
    "    sumE = photon_E[0] + photon_E[1] # energy of diphoton system\n",
    "    return math.sqrt(sumE**2 - sump**2)/1000 #/1000 to go from MeV to GeV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing an already uncommented cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you change a cut: Cell -> Run All Below\n",
    "\n",
    "If you uncomment a cut here, you also need to uncomment the corresponding cut in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut on number of photons\n",
    "# paper: \"The data used in this channel are selected using a diphoton trigger, which requires two clusters\"\n",
    "def cut_photon_n (photon_n):\n",
    "# want to throw away events where photon_n does not equal 2\n",
    "# exclamation mark (!) means \"not\"\n",
    "# so != means \"not equal to\"\n",
    "    return photon_n != 2\n",
    "\n",
    "# Cut on pseudorapidity outside the fiducial region\n",
    "# paper: \"Photon candidates are reconstructed in the fiducial region |η| < 2.37\"\n",
    "def cut_photon_eta_fiducial(photon_eta):\n",
    "# want to throw away events where modulus of photon_eta > 2.37\n",
    "    return photon_eta[0] > 2.37 or photon_eta[1] > 2.37 or photon_eta[0] < -2.37 or photon_eta[1] < -2.37\n",
    "\n",
    "# Cut on pseudorapidity in barrel/end-cap transition region\n",
    "# paper: \"excluding the calorimeter barrel/end-cap transition region 1.37 < |η| < 1.52\"\n",
    "def cut_photon_eta_transition(photon_eta):\n",
    "# want to throw away events where modulus of photon_eta between 1.37 and 1.52\n",
    "    if photon_eta[0] < 1.52 and photon_eta[0] > 1.37: return True # True means throw away\n",
    "    elif photon_eta[1] < 1.52 and photon_eta[1] > 1.37: return True\n",
    "    elif photon_eta[0] > -1.52 and photon_eta[0] < -1.37: return True\n",
    "    elif photon_eta[1] < -1.37 and photon_eta[1] > -1.52: return True\n",
    "    else: return False\n",
    "    \n",
    "# Cut on Transverse momentum\n",
    "# paper: \"The leading (sub-leading) photon candidate is required to have ET > 40 GeV (30 GeV)\"\n",
    "def cut_photon_pt(photon_pt):\n",
    "# want to throw away events where photon_pt[0] < 40000 MeV or photon_pt[1] < 30000 MeV\n",
    "# first photon is [0], 2nd photon is [1] etc\n",
    "    return photon_pt[0] < 40000 or photon_pt[1] < 30000\n",
    "\n",
    "# Cut on photon reconstruction quality\n",
    "# paper: \"Photon candidates are required to pass identification criteria\"\n",
    "def cut_photon_reconstruction(photon_isTightID):\n",
    "# isTightID == True means a photon that has been identified as being well reconstructed\n",
    "# want to throw away events where it is false for one or both photons\n",
    "    return photon_isTightID[0] == False or photon_isTightID[1] == False\n",
    "\n",
    "# Cut on energy isolation\n",
    "# paper: \"Photon candidates are required to have an isolation transverse energy of less than 4 GeV\"\n",
    "def cut_isolation_et(photon_etcone20):\n",
    "# want to throw away events where isolation eT > 4000 MeV\n",
    "    return photon_etcone20[0] > 4000 or photon_etcone20[1] > 4000\n",
    "    \n",
    "# Cut on reconstructed invariant mass lower limit\n",
    "# paper: \"in the diphoton invariant mass range between 100 GeV and 160 GeV\"\n",
    "def cut_mass_lower(myy):\n",
    "# want to throw away minimum invariant reconstructed mass < 100 GeV\n",
    "    return myy < 100\n",
    "\n",
    "# Cut on reconstructed invariant mass upper limit\n",
    "# paper: \"in the diphoton invariant mass range between 100 GeV and 160 GeV\"\n",
    "def cut_mass_upper(myy):\n",
    "# want to throw away maximum invariant reconstructed mass > 160 GeV\n",
    "    return myy > 160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncommenting a new cut \n",
    "\n",
    "If you add a cut: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time() # start the clock\n",
    "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
    "    data_all = pd.DataFrame() # define empty pandas DataFrame to hold all data for this sample\n",
    "    mc = uproot.open(path)[\"mini\"] # open the tree called mini\n",
    "    numevents = uproot.numentries(path, \"mini\") # number of events\n",
    "    for data in mc.iterate([\"photon_n\",\"photon_trigMatched\",\"photon_pt\",\"photon_eta\",\"photon_phi\",\"photon_E\",\n",
    "                            \"photon_isTightID\",\"photon_etcone20\"], # add more variables here if you want to use them\n",
    "                           flatten=False, # make JaggedArrays lists\n",
    "                           entrysteps=2500000, # number of events in a batch to process\n",
    "                           outputtype=pd.DataFrame, # choose output type as pandas DataFrame\n",
    "                           entrystop=numevents*fraction): # process up to numevents*fraction\n",
    "\n",
    "        nIn = len(data.index) # number of events in this batch\n",
    "        print('\\t initial number of events:\\t\\t\\t\\t',nIn)\n",
    "        \n",
    "        # Cut on number of photons using the function cut_photon_n defined above\n",
    "        fail = data[ np.vectorize(cut_photon_n)(data.photon_n)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after requiring exactly 2 photons:\\t\\t\\t',len(data.index))\n",
    "        \n",
    "        # Cut on photon reconstruction quality using the function cut_photon_reconstruction defined above\n",
    "        fail = data[ np.vectorize(cut_photon_reconstruction)(data.photon_isTightID)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after requiring tight photons:\\t\\t\\t\\t',len(data.index))\n",
    "        \n",
    "        # Cut on transverse momentum of the photons using the function cut_photon_pt defined above\n",
    "        fail = data[ np.vectorize(cut_photon_pt)(data.photon_pt)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after photon pt requirement:\\t\\t\\t\\t',len(data.index))\n",
    "        \n",
    "        # Cut on energy isolation using the function cut_isolation_et defined above\n",
    "        fail = data[ np.vectorize(cut_isolation_et)(data.photon_etcone20)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after photon isolation requirement:\\t\\t\\t',len(data.index))\n",
    "        \n",
    "        # Cut on pseudorapidity outside fiducial region using the function cut_photon_eta_fiducial defined above\n",
    "        fail = data[ np.vectorize(cut_photon_eta_fiducial)(data.photon_eta)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after requiring photons within fiducial region:\\t',len(data.index))\n",
    "        \n",
    "        # Cut on pseudorapidity inside barrel/end-cap transition region using the function cut_photon_eta_transition\n",
    "        fail = data[ np.vectorize(cut_photon_eta_transition)(data.photon_eta)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after throwing away photons in transition region:\\t',len(data.index))\n",
    "        \n",
    "        # Calculate reconstructed diphoton invariant mass using the function calc_myy defined above\n",
    "        data['myy'] = np.vectorize(calc_myy)(data.photon_pt,data.photon_eta,data.photon_phi,data.photon_E)\n",
    "\n",
    "        # Cut on lower limit of reconstructed invariant mass using the function cut_mass_lower\n",
    "        fail = data[ np.vectorize(cut_mass_lower)(data.myy)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after cut on diphoton mass lower limit:\\t\\t',len(data.index))\n",
    "        # Cut on upper limit of reconsructed invariant mass using the function cut_mass_upper\n",
    "        fail = data[ np.vectorize(cut_mass_upper)(data.myy)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after cut on diphoton mass upper limit:\\t\\t',len(data.index))\n",
    "\n",
    "        # dataframe contents can be printed at any stage like this\n",
    "        #print(data)\n",
    "\n",
    "        # dataframe column can be printed at any stage like this\n",
    "        #print(data['photon_pt'])\n",
    "\n",
    "        # multiple dataframe columns can be printed at any stage like this\n",
    "        #print(data[['photon_pt','photon_eta']])\n",
    "\n",
    "        nOut = len(data.index) # number of events passing cuts in this batch\n",
    "        data_all = data_all.append(data) # append dataframe from this batch to the dataframe for the whole sample\n",
    "        elapsed = time.time() - start # time taken to process\n",
    "        print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
    "    \n",
    "    return data_all # return dataframe containing events passing all cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the processing happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a change to plotting\n",
    "If you only want a make a change in the plot: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myy = { # dictionary containing plotting parameters for the myy histogram\n",
    "    # change plotting parameters                                                                                                     \n",
    "    'bin_width':2, # width of each histogram bin\n",
    "    'num_bins':30, # number of histogram bins\n",
    "    'xrange_min':100, # minimum on the x-axis\n",
    "    'xlabel':r'$\\mathrm{m_{\\gamma\\gamma}}$ [GeV]', # x-axis label\n",
    "\n",
    "    # change aesthetic parameters if you want                                                                                        \n",
    "    'y_label_x_position':-0.09, # 0.09 to the left of y axis                                                                         \n",
    "    'legend_loc':'lower left',                      \n",
    "    'linear_top_margin':1.1 # to decrease the separation between data and the top of the figure, pick a number closer to 1           \n",
    "}\n",
    "\n",
    "hist_dict = {'myy': myy} # add a histogram here if you want it plotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "    \n",
    "    plot_label = r'$H \\rightarrow \\gamma\\gamma$' # label to write on the plot\n",
    "    \n",
    "    # *******************\n",
    "    # general definitions (shouldn't need to change)\n",
    "    lumi_used = str(lumi*fraction) # luminosity to write on the plot   \n",
    "\n",
    "    for x_variable,hist in hist_dict.items(): # access the dictionary of histograms defined in the cell above\n",
    "\n",
    "        h_bin_width = hist['bin_width'] # get the bin width defined in the cell above\n",
    "        h_num_bins = hist['num_bins'] # get the number of bins defined in the cell above\n",
    "        h_xrange_min = hist['xrange_min'] # get the x-range minimum defined in the cell above\n",
    "        h_xlabel = hist['xlabel'] # get the x-axis label defined in the cell above\n",
    "        h_y_label_x_position = hist['y_label_x_position'] # get the x-position of the y-axis label defined in the cell above\n",
    "        h_legend_loc = hist['legend_loc'] # get the legend location defined in the cell above\n",
    "        h_linear_top_margin = hist['linear_top_margin'] # to decrease the separation between data and the top of the figure, pick a number closer to 1\n",
    "\n",
    "        bins = [ h_xrange_min + x*h_bin_width for x in range(h_num_bins+1) ] # bin limits\n",
    "        bin_centres = [ h_xrange_min+h_bin_width/2 + x*h_bin_width for x in range(h_num_bins) ] # bin centres\n",
    "\n",
    "        data_x,_ = np.histogram( data['data'][x_variable].values, bins=bins ) # histogram the data\n",
    "        data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "    \n",
    "        # data fit\n",
    "        polynomial_mod = PolynomialModel( 4 ) # 4th order polynomial\n",
    "        gaussian_mod = GaussianModel() # Gaussian\n",
    "        bin_centres_array = np.asarray(bin_centres) # array of bin centres\n",
    "        # set initial guesses for the parameters of the polynomial model\n",
    "        pars = polynomial_mod.guess(data_x, # data to use to guess parameter values\n",
    "                                    x=bin_centres_array, c0=data_x.max(), c1=0, c2=0, c3=0, c4=0 )\n",
    "        # set initial guesses for the parameters of the Gaussian model\n",
    "        pars += gaussian_mod.guess(data_x, # data to use to guess parameter values\n",
    "                                   x=bin_centres_array, amplitude=91.7, center=125., sigma=2.4 )\n",
    "        model = polynomial_mod + gaussian_mod # combined model\n",
    "        out = model.fit(data_x, # data to be fit\n",
    "                        pars, # guesses for the parameters\n",
    "                        x=bin_centres_array, weights=1/data_x_errors ) # fit the model to the data\n",
    "    \n",
    "        # background part of fit\n",
    "        params_dict = out.params.valuesdict() # get the parameters from the fit to data\n",
    "        c0 = params_dict['c0'] # c0 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "        c1 = params_dict['c1'] # c1 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "        c2 = params_dict['c2'] # c2 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "        c3 = params_dict['c3'] # c3 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "        c4 = params_dict['c4'] # c4 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "        # get the background only part of the fit to data\n",
    "        background = c0 + c1*bin_centres_array + c2*bin_centres_array**2 + c3*bin_centres_array**3 + c4*bin_centres_array**4\n",
    "\n",
    "        signal_x = data_x - background # data fit - background fit = signal fit\n",
    "    \n",
    "    \n",
    "        # *************\n",
    "        # Main plot \n",
    "        # *************\n",
    "        plt.axes([0.1,0.3,0.85,0.65]) # left, bottom, width, height \n",
    "        main_axes = plt.gca() # get current axes\n",
    "        # plot the data points\n",
    "        main_axes.errorbar( x=bin_centres, y=data_x, yerr=data_x_errors, fmt='ko', label='Data' ) \n",
    "        # plot the signal + background fit\n",
    "        main_axes.plot(bin_centres, # x\n",
    "                       out.best_fit, # y\n",
    "                       '-r', # single red line\n",
    "                       label='Sig+Bkg Fit ($m_H=125$ GeV)' )\n",
    "        # plot the background only fit\n",
    "        main_axes.plot(bin_centres, # x\n",
    "                       background, # y\n",
    "                       '--r', # dashed red line\n",
    "                       label='Bkg (4th order polynomial)' )\n",
    "        \n",
    "        main_axes.set_xlim( left=h_xrange_min, right=bins[-1] ) # set the x-limit of the main axes\n",
    "        main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) # separation of x axis minor ticks\n",
    "        # set the axis tick parameters for the main axes\n",
    "        main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                              direction='in', # Put ticks inside and outside the axes\n",
    "                              top=True, # draw ticks on the top axis\n",
    "                              labeltop=False, # don't draw tick labels on top axis\n",
    "                              labelbottom=False, # don't draw tick labels on bottom axis\n",
    "                              right=True, # draw ticks on right axis\n",
    "                              labelright=False ) # don't draw tick labels on right axis\n",
    "        if len( h_xlabel.split('[') ) > 1: # if x-axis has units\n",
    "            y_units = ' '+h_xlabel[h_xlabel.find('[')+1:h_xlabel.find(']')]\n",
    "        else: y_units = '' # if x-axis is unitless\n",
    "        main_axes.set_ylabel('Events / '+str(h_bin_width)+y_units, fontname='sans-serif',\n",
    "                             horizontalalignment='right', y=1.0, fontsize=11 ) # write y-axis label for main axes\n",
    "        main_axes.set_ylim( bottom=0, top=(np.amax(data_x)+math.sqrt(np.amax(data_x)))*h_linear_top_margin ) # set the y axis limit for the main axes\n",
    "        main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) # set minor ticks on the y axis of the main axes\n",
    "        main_axes.yaxis.get_major_ticks()[0].set_visible(False) # avoid displaying y=0 on the main axes\n",
    "        \n",
    "        # Add text 'ATLAS Open Data' on plot\n",
    "        plt.text(0.2, # x\n",
    "                 0.97, # y\n",
    "                 'ATLAS Open Data', # text\n",
    "                 transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "                 horizontalalignment='left', verticalalignment='top', family='sans-serif', fontsize=13 ) \n",
    "        # Add text 'for education' on plot\n",
    "        plt.text(0.2, # x\n",
    "                 0.9, # y\n",
    "                 'for education', # text\n",
    "                 transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "                 horizontalalignment='left', verticalalignment='top', family='sans-serif', style='italic',\n",
    "                 fontsize=8 ) \n",
    "        # Add energy and luminosity\n",
    "        plt.text(0.2, # x\n",
    "                 0.86, # y\n",
    "                 '$\\sqrt{s}=13\\,\\mathrm{TeV},\\;\\int L\\,dt=$'+lumi_used+'$\\,\\mathrm{fb}^{-1}$', # text\n",
    "                 transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "                 horizontalalignment='left', verticalalignment='top', family='sans-serif' ) \n",
    "        # Add a label for the analysis carried out\n",
    "        plt.text(0.2, # x\n",
    "                 0.78, # y\n",
    "                 plot_label, # text \n",
    "                 transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "                 horizontalalignment='left', verticalalignment='top', family='sans-serif' ) \n",
    "    \n",
    "        # draw the legend\n",
    "        main_axes.legend(frameon=False, # no box around the legend\n",
    "                         loc=h_legend_loc ) # legend location \n",
    "    \n",
    "    \n",
    "        # *************\n",
    "        # Data-Bkg plot \n",
    "        # *************\n",
    "        plt.axes([0.1,0.1,0.85,0.2]) # left, bottom, width, height\n",
    "        sub_axes = plt.gca() # get the current axes\n",
    "        sub_axes.yaxis.set_major_locator( MaxNLocator(nbins='auto', symmetric=True) ) # set the y axis to be symmetric about Data-Background=0\n",
    "        sub_axes.errorbar( x=bin_centres, y=signal_x, yerr=data_x_errors, fmt='ko' ) # plot Data-Background\n",
    "        # draw the fit to data\n",
    "        sub_axes.plot(bin_centres, # x\n",
    "                      out.best_fit-background, # y\n",
    "                      '-r' ) # single red line\n",
    "        # draw the background only fit\n",
    "        sub_axes.plot(bin_centres, # x\n",
    "                      background-background, # y\n",
    "                      '--r' )  # dashed red line\n",
    "        sub_axes.set_xlim( left=h_xrange_min, right=bins[-1] ) # set the x-axis limits on the sub axes\n",
    "        sub_axes.xaxis.set_minor_locator( AutoMinorLocator() ) # separation of x-axis minor ticks\n",
    "        sub_axes.xaxis.set_label_coords( 0.9,-0.2 ) # (x,y) of x axis label # 0.2 down from x-axis\n",
    "        sub_axes.set_xlabel( h_xlabel, fontname='sans-serif', fontsize=11 ) # x-axis label\n",
    "        # set the tick parameters for the sub axes\n",
    "        sub_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                             direction='in', # Put ticks inside and outside the axes\n",
    "                             top=True, # draw ticks on the top axis\n",
    "                             labeltop=False, # don't draw tick labels on top axis\n",
    "                             right=True, # draw ticks on right axis\n",
    "                             labelright=False ) # don't draw tick labels on right axis \n",
    "        sub_axes.yaxis.set_minor_locator( AutoMinorLocator() ) # separation of y-axis minor ticks\n",
    "        sub_axes.set_ylabel( 'Events-Bkg', fontname='sans-serif', x=1, fontsize=11 ) # y-axis label on the sub axes\n",
    "        \n",
    "        \n",
    "        # Generic features for both plots\n",
    "        main_axes.yaxis.set_label_coords( h_y_label_x_position, 1 ) # x,y coordinates of the y-axis label on the main axes\n",
    "        sub_axes.yaxis.set_label_coords( h_y_label_x_position, 0.5 ) # x,y coordinates of the y-axis label on the sub axes\n",
    "\n",
    "        plt.savefig( 'Hyy_'+x_variable+'.pdf', bbox_inches='tight' ) # save the plot\n",
    "    \n",
    "        print( 'chi^2 = ' + str(out.chisqr) ) # get the chi squared of the fit\n",
    "        print( 'gaussian centre = ' + str(params_dict['center']) ) # centre of the fitted Gaussian\n",
    "        print( 'gaussian sigma = ' + str(params_dict['sigma']) ) # sigma of the fitted Gaussian\n",
    "        print( 'gaussian fwhm = ' + str(params_dict['fwhm']) ) # Full-Width-at-Half-Maximum of the fitted Gaussian\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
