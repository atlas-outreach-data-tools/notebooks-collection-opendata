{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"../../images/ATLASOD.gif\" style=\"width:50%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to rediscover the Higgs boson yourself!\n",
    "This notebook uses ATLAS Open Data http://opendata.atlas.cern to show you the steps to rediscover the Higgs boson yourself!\n",
    "\n",
    "The idea is that cuts increase the ratio of signal ($H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$) to background ($Z, t\\bar{t}, ZZ \\rightarrow \\ell\\ell\\ell\\ell$)\n",
    "\n",
    "First, the amount of $Z$ and $t\\bar{t}$ background is reduced, since these are quite different to the signal.\n",
    "\n",
    "Then, the amount of $ZZ \\rightarrow \\ell\\ell\\ell\\ell$ is reduced, whilst keeping $H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$ signal\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 4 leptons per event, so that processing is quicker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"HZZ_feynman.png\" style=\"width:40%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time setup on your computer\n",
    "This first cell only needs to be run the first time you open this notebook on your computer. \n",
    "\n",
    "If you close Jupyter and re-open on the same computer, you won't need to run this first cell again.\n",
    "\n",
    "If you open on binder, you don't need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --user pip\n",
    "!{sys.executable} -m pip install -r ../../requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To setup everytime\n",
    "Cell -> Run All Below\n",
    "\n",
    "to be done every time you re-open this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches # for \"Total SM & uncertainty\" merged legend handle\n",
    "from matplotlib.lines import Line2D # for dashed line in legend\n",
    "from matplotlib.ticker import AutoMinorLocator,LogLocator,LogFormatterSciNotation # for minor ticks\n",
    "\n",
    "import infofile\n",
    "import labelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumi = 10 # 10 fb-1\n",
    "\n",
    "fraction = 1 # reduce this is you want the code to run quicker\n",
    "                                                                                                                                  \n",
    "#tuple_path = \"Input/4lep/\" # local \n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/4lep/\" # web address\n",
    "\n",
    "stack_order = [r'$Z,t\\bar{t}$','ZZ'] # put smallest contribution first, then increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['data_A','data_B','data_C','data_D']\n",
    "    },\n",
    "\n",
    "    r'$Z,t\\bar{t}$' : {\n",
    "        'list' : ['Zee','Zmumu','ttbar_lep'],\n",
    "        'color' : \"#6b59d3\"\n",
    "    },\n",
    "\n",
    "    'ZZ' : {\n",
    "        'list' : ['llll'],\n",
    "        'color' : \"#ff0000\"\n",
    "    },\n",
    "\n",
    "    r'$H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$' : {\n",
    "        'list' : ['ggH125_ZZ4lep','VBFH125_ZZ4lep','WH125_ZZ4lep','ZH125_ZZ4lep'],\n",
    "        'color' : \"#00cdff\"\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sample(s):\n",
    "    print('Processing '+s+' samples')\n",
    "    frames = []\n",
    "    for val in samples[s]['list']:\n",
    "        prefix = \"MC/mc_\"\n",
    "        if s == 'data':\n",
    "            prefix = \"Data/\"\n",
    "        else: prefix += str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "        fileString = tuple_path+prefix+val+\".4lep.root\" # change ending depending on collection used, e.g. .4lep.root\n",
    "        if fileString != \"\":\n",
    "            temp = read_file(fileString,val)\n",
    "            frames.append(temp)\n",
    "        else:\n",
    "            print(\"Error: \"+val+\" not found!\")\n",
    "    data_s = pd.concat(frames)\n",
    "    return data_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    data = {}\n",
    "    for s in samples:\n",
    "        data[s] = read_sample(s)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(mcWeight,scaleFactor_PILEUP,scaleFactor_ELE,\n",
    "                scaleFactor_MUON, scaleFactor_LepTRIGGER):\n",
    "    return mcWeight*scaleFactor_PILEUP*scaleFactor_ELE*scaleFactor_MUON*scaleFactor_LepTRIGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xsec_weight(totalWeight,sample):\n",
    "    info = infofile.infos[sample]\n",
    "    weight = (lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
    "    weight *= totalWeight\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mllll(lep_pts,lep_etas,lep_phis):\n",
    "    theta_0 = 2*math.atan(math.exp(-lep_etas[0]))\n",
    "    theta_1 = 2*math.atan(math.exp(-lep_etas[1]))\n",
    "    theta_2 = 2*math.atan(math.exp(-lep_etas[2]))\n",
    "    theta_3 = 2*math.atan(math.exp(-lep_etas[3]))\n",
    "    p_0 = lep_pts[0]/math.sin(theta_0)\n",
    "    p_1 = lep_pts[1]/math.sin(theta_1)\n",
    "    p_2 = lep_pts[2]/math.sin(theta_2)\n",
    "    p_3 = lep_pts[3]/math.sin(theta_3)\n",
    "    pz_0 = p_0*math.cos(theta_0)\n",
    "    pz_1 = p_1*math.cos(theta_1)\n",
    "    pz_2 = p_2*math.cos(theta_2)\n",
    "    pz_3 = p_3*math.cos(theta_3)\n",
    "    px_0 = p_0*math.sin(theta_0)*math.cos(lep_phis[0])\n",
    "    px_1 = p_1*math.sin(theta_1)*math.cos(lep_phis[1])\n",
    "    px_2 = p_2*math.sin(theta_2)*math.cos(lep_phis[2])\n",
    "    px_3 = p_3*math.sin(theta_3)*math.cos(lep_phis[3])\n",
    "    py_0 = p_0*math.sin(theta_0)*math.sin(lep_phis[0])\n",
    "    py_1 = p_1*math.sin(theta_1)*math.sin(lep_phis[1])\n",
    "    py_2 = p_2*math.sin(theta_2)*math.sin(lep_phis[2])\n",
    "    py_3 = p_3*math.sin(theta_3)*math.sin(lep_phis[3])\n",
    "    sumpz = pz_0 + pz_1 + pz_2 + pz_3\n",
    "    sumpx = px_0 + px_1 + px_2 + px_3\n",
    "    sumpy = py_0 + py_1 + py_2 + py_3\n",
    "    sumE = p_0 + p_1 + p_2 + p_3\n",
    "    mllll = sumE**2 - sumpz**2 - sumpx**2 - sumpy**2\n",
    "    return math.sqrt(mllll)/1000 #/1000 to go from MeV to GeV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing an already uncommented cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you change a cut: Cell -> Run All Below\n",
    "\n",
    "If you uncomment a cut here, you also need to uncomment the corresponding cut in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut on number of leptons\n",
    "def cut_n_lep(lep_n):\n",
    "    # exclamation mark (!) means \"not\"\n",
    "    # so != means \"not equal to\"\n",
    "    # return when number of leptons is not equal to 4 \n",
    "    return lep_n != 4\n",
    "\n",
    "# cut on lepton charge\n",
    "def cut_lep_charge(lep_charge):\n",
    "    # return when sum of lepton charges is not equal to 0\n",
    "    # first lepton is [0], 2nd lepton is [1] etc\n",
    "    return lep_charge[0] + lep_charge[1] + lep_charge[2] + lep_charge[3] != 0\n",
    "\n",
    "#cut on transverse momentum of the leptons\n",
    "def cut_lep_pt_012(lep_pt):\n",
    "#want to throw away any events where lep_pt[1] < 15000\n",
    "#want to throw away any events where lep_pt[2] < 10000\n",
    "    return lep_pt[1] < 15000 or lep_pt[2] < 10000\n",
    "\n",
    "# cut on lepton type\n",
    "def cut_lep_type(lep_type):\n",
    "# for an electron lep_type is 11\n",
    "# for a muon lep_type is 13\n",
    "    sum_lep_type = lep_type[0] + lep_type[1] + lep_type[2] + lep_type[3]\n",
    "    return (sum_lep_type != 44) and (sum_lep_type != 48) and (sum_lep_type != 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncommenting a new cut\n",
    "If you add a cut: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time()\n",
    "    print(\"\\tProcessing: \"+sample+\" file\")\n",
    "    data_all = pd.DataFrame()\n",
    "    mc = uproot.open(path)[\"mini\"]\n",
    "    numevents = uproot.numentries(path, \"mini\")\n",
    "    for data in mc.iterate([\"lep_n\",\"lep_pt\",\"lep_eta\",\"lep_phi\",\"lep_charge\",\"lep_type\",\"lep_ptcone30\",\"lep_etcone20\",\n",
    "                         \"mcWeight\",\"scaleFactor_PILEUP\",\"scaleFactor_ELE\",\"scaleFactor_MUON\", # add more variables here if you make cuts on them ,  \n",
    "                         \"scaleFactor_LepTRIGGER\"], flatten=False, entrysteps=2500000, outputtype=pd.DataFrame, entrystop=numevents*fraction):\n",
    "\n",
    "        nIn = len(data.index)\n",
    "\n",
    "        if 'data' not in sample:\n",
    "            data['totalWeight'] = np.vectorize(calc_weight)(data.mcWeight,data.scaleFactor_PILEUP,data.scaleFactor_ELE,data.scaleFactor_MUON,data.scaleFactor_LepTRIGGER)\n",
    "            data['totalWeight'] = np.vectorize(get_xsec_weight)(data.totalWeight,sample)\n",
    "            \n",
    "        data.drop([\"mcWeight\",\"scaleFactor_PILEUP\",\"scaleFactor_ELE\",\"scaleFactor_MUON\",\"scaleFactor_LepTRIGGER\"], axis=1, inplace=True)\n",
    "\n",
    "        # cut on number of leptons\n",
    "        fail =data[ np.vectorize(cut_n_lep)(data.lep_n)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # cut on lepton charge\n",
    "        fail = data[ np.vectorize(cut_lep_charge)(data.lep_charge) ].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        #cut on the transverse momentum of the leptons\n",
    "        fail =data[ np.vectorize(cut_lep_pt_012)(data.lep_pt)].index\n",
    "        data.drop(fail,inplace=True)\n",
    "\n",
    "        # cut on lepton type\n",
    "        fail = data[ np.vectorize(cut_lep_type)(data.lep_type) ].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # calculation of 4-lepton invariant mass\n",
    "        data['mllll'] = np.vectorize(calc_mllll)(data.lep_pt,data.lep_eta,data.lep_phi)\n",
    "\n",
    "        #print(data[['lep_eta']])\n",
    "\n",
    "        nOut = len(data.index)\n",
    "        data_all = data_all.append(data)\n",
    "        elapsed = time.time() - start\n",
    "        print(\"\\t\\t\"+sample+\" time taken: \"+str(elapsed)+\"s, nIn: \"+str(nIn)+\", nOut: \"+str(nOut))\n",
    "    \n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data = get_data_from_files()\n",
    "elapsed = time.time() - start\n",
    "print(\"Time taken: \"+str(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a change to plotting\n",
    "If you only want a make a change in plotting: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mllll = {\n",
    "    # change plotting parameters\n",
    "    'bin_width':5,\n",
    "    'num_bins':34,\n",
    "    'xrange_min':80,\n",
    "    'log_y':False,\n",
    "\n",
    "    # change aesthetic parameters if you want\n",
    "    'y_label_x_position':-0.09, # 0.09 to the left of y axis\n",
    "    'legend_loc':'best',\n",
    "    'log_top_margin':10000, # to decrease the separation between data and the top of the figure, remove a 0\n",
    "    'linear_top_margin':1.4 # to decrease the separation between data and the top of the figure, pick a number closer to 1\n",
    "}\n",
    "\n",
    "hist_dict = {'mllll':mllll} # add a histogram here if you want it plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "\n",
    "    signal_format = 'hist' # 'line' or 'hist' or None\n",
    "    Total_SM_label = False # for Total SM black line in plot and legend\n",
    "    plot_label = r'$H \\rightarrow ZZ^* \\rightarrow \\ell\\ell\\ell\\ell$'\n",
    "    signal_label = r'Signal ($m_H=125$ GeV)'\n",
    "\n",
    "    # *******************\n",
    "    # general definitions (shouldn't need to change)\n",
    "    lumi_used = str(lumi*fraction)    \n",
    "    signal = None\n",
    "    for s in samples.keys():\n",
    "        if s not in stack_order and s!='data': signal = s\n",
    "\n",
    "    for x_variable,hist in hist_dict.items():\n",
    "\n",
    "        h_bin_width = hist['bin_width']\n",
    "        h_num_bins = hist['num_bins']\n",
    "        h_xrange_min = hist['xrange_min']\n",
    "        h_log_y = hist['log_y']\n",
    "        h_y_label_x_position = hist['y_label_x_position']\n",
    "        h_legend_loc = hist['legend_loc']\n",
    "        h_log_top_margin = hist['log_top_margin'] # to decrease the separation between data and the top of the figure, remove a 0\n",
    "        h_linear_top_margin = hist['linear_top_margin'] # to decrease the separation between data and the top of the figure, pick a number closer to 1\n",
    "    \n",
    "        bins = [h_xrange_min + x*h_bin_width for x in range(h_num_bins+1) ]\n",
    "        bin_centres = [h_xrange_min+h_bin_width/2 + x*h_bin_width for x in range(h_num_bins) ]\n",
    "\n",
    "        data_x,_ = np.histogram(data['data'][x_variable].values, bins=bins)\n",
    "        data_x_errors = np.sqrt(data_x)\n",
    "\n",
    "        signal_x = None\n",
    "        if signal_format=='line':\n",
    "            signal_x,_ = np.histogram(data[signal][x_variable].values,bins=bins,weights=data[signal].totalWeight.values)\n",
    "        elif signal_format=='hist':\n",
    "            signal_x = data[signal][x_variable].values\n",
    "            signal_weights = data[signal].totalWeight.values\n",
    "            signal_color = samples[signal]['color']\n",
    "    \n",
    "        mc_x = []\n",
    "        mc_weights = []\n",
    "        mc_colors = []\n",
    "        mc_labels = []\n",
    "        mc_x_tot = np.zeros(len(bin_centres))\n",
    "\n",
    "        for s in stack_order:\n",
    "            mc_labels.append(s)\n",
    "            mc_x.append(data[s][x_variable].values)\n",
    "            mc_colors.append(samples[s]['color'])\n",
    "            mc_weights.append(data[s].totalWeight.values)\n",
    "            mc_x_heights,_ = np.histogram(data[s][x_variable].values,bins=bins,weights=data[s].totalWeight.values)\n",
    "            mc_x_tot = np.add(mc_x_tot, mc_x_heights)\n",
    "    \n",
    "        mc_x_err = np.sqrt(mc_x_tot)\n",
    "    \n",
    "    \n",
    "        # *************\n",
    "        # Main plot \n",
    "        # *************\n",
    "        plt.clf()\n",
    "        plt.axes([0.1,0.3,0.85,0.65]) #(left, bottom, width, height)\n",
    "        main_axes = plt.gca()\n",
    "        main_axes.errorbar( x=bin_centres, y=data_x, yerr=data_x_errors, fmt='ko', label='Data')\n",
    "        mc_heights = main_axes.hist(mc_x,bins=bins,weights=mc_weights,stacked=True,color=mc_colors, label=mc_labels)\n",
    "        if Total_SM_label:\n",
    "            totalSM_handle, = main_axes.step(bins,np.insert(mc_x_tot,0,mc_x_tot[0]),color='black')\n",
    "        if signal_format=='line':\n",
    "            main_axes.step(bins,np.insert(signal_x,0,signal_x[0]),color=samples[signal]['color'], linestyle='--',\n",
    "                       label=signal)\n",
    "        elif signal_format=='hist':\n",
    "            main_axes.hist(signal_x,bins=bins,bottom=mc_x_tot,weights=signal_weights,color=signal_color,label=signal)\n",
    "        main_axes.bar(bin_centres,2*mc_x_err,bottom=mc_x_tot-mc_x_err,alpha=0.5,color='none',hatch=\"////\",\n",
    "                  width=h_bin_width, label='Stat. Unc.')\n",
    "        \n",
    "        main_axes.set_xlim(left=h_xrange_min,right=bins[-1])\n",
    "        main_axes.xaxis.set_minor_locator(AutoMinorLocator()) # separation of x axis minor ticks\n",
    "        main_axes.tick_params(which='both',direction='in',top=True,labeltop=False,labelbottom=False,right=True,labelright=False)\n",
    "        if len(labelfile.variable_labels[x_variable].split('['))>1:\n",
    "            y_units = ' '+labelfile.variable_labels[x_variable][labelfile.variable_labels[x_variable].find(\"[\")+1:labelfile.variable_labels[x_variable].find(\"]\")]\n",
    "        else: y_units = ''\n",
    "        main_axes.set_ylabel(r'Events / '+str(h_bin_width)+y_units,fontname='sans-serif',horizontalalignment='right',y=1.0,fontsize=11)\n",
    "        if h_log_y:\n",
    "            main_axes.set_yscale('log')\n",
    "            smallest_contribution = mc_heights[0][0]\n",
    "            smallest_contribution.sort()\n",
    "            bottom = smallest_contribution[-2]\n",
    "            top = np.amax(data_x)*h_log_top_margin\n",
    "            main_axes.set_ylim(bottom=bottom,top=top)\n",
    "            main_axes.yaxis.set_major_formatter(CustomTicker())\n",
    "            locmin = LogLocator(base=10.0,subs=(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9),numticks=12)\n",
    "            main_axes.yaxis.set_minor_locator(locmin)\n",
    "        else: \n",
    "            main_axes.set_ylim(bottom=0,top=(np.amax(data_x)+math.sqrt(np.amax(data_x)))*h_linear_top_margin)\n",
    "            main_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        \n",
    "        plt.text(0.05,0.97,'ATLAS',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes,style='italic',weight='bold',fontsize=13)\n",
    "        plt.text(0.19,0.97,'Open Data',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes,fontsize=13)\n",
    "        plt.text(0.05,0.9,'for education only',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes,style='italic',fontsize=8)\n",
    "        plt.text(0.05,0.86,r'$\\sqrt{s}=13\\,\\mathrm{TeV},\\;\\int L\\,dt=$'+lumi_used+'$\\,\\mathrm{fb}^{-1}$',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes)\n",
    "        plt.text(0.05,0.78,plot_label,ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes)\n",
    "    \n",
    "        # Create new legend handles but use the colors from the existing ones \n",
    "        handles, labels = main_axes.get_legend_handles_labels()\n",
    "        if signal_format=='line':\n",
    "            handles[labels.index(signal)] = Line2D([], [], c=samples[signal]['color'], linestyle='dashed')\n",
    "        if Total_SM_label:\n",
    "            uncertainty_handle = mpatches.Patch(facecolor='none',hatch='////')\n",
    "            handles.append((totalSM_handle,uncertainty_handle))\n",
    "            labels.append('Total SM')\n",
    "    \n",
    "        # specify order within legend\n",
    "        new_handles = [handles[labels.index('Data')]]\n",
    "        new_labels = ['Data']\n",
    "        for s in reversed(stack_order):\n",
    "            new_handles.append(handles[labels.index(s)])\n",
    "            new_labels.append(s)\n",
    "        if Total_SM_label:\n",
    "            new_handles.append(handles[labels.index('Total SM')])\n",
    "            new_labels.append('Total SM')\n",
    "        else: \n",
    "            new_handles.append(handles[labels.index('Stat. Unc.')])\n",
    "            new_labels.append('Stat. Unc.')\n",
    "        if signal is not None:\n",
    "            new_handles.append(handles[labels.index(signal)])\n",
    "            new_labels.append(signal_label)\n",
    "        main_axes.legend(handles=new_handles, labels=new_labels, frameon=False, loc=h_legend_loc)\n",
    "    \n",
    "    \n",
    "        # *************\n",
    "        # Data/MC ratio \n",
    "        # *************\n",
    "        plt.axes([0.1,0.1,0.85,0.2]) #(left, bottom, width, height)\n",
    "        ratio_axes = plt.gca()\n",
    "        ratio_axes.errorbar( x=bin_centres, y=data_x/mc_x_tot, yerr=data_x_errors/mc_x_tot, fmt='ko')\n",
    "        ratio_axes.bar(bin_centres,2*mc_x_err/mc_x_tot,bottom=1-mc_x_err/mc_x_tot,alpha=0.5,color='none',\n",
    "            hatch=\"////\",width=h_bin_width)\n",
    "        ratio_axes.plot(bins,np.ones(len(bins)),color='k')\n",
    "        ratio_axes.set_xlim(left=h_xrange_min,right=bins[-1])\n",
    "        ratio_axes.xaxis.set_minor_locator(AutoMinorLocator()) # separation of x axis minor ticks\n",
    "        ratio_axes.xaxis.set_label_coords(0.9,-0.2) # (x,y) of x axis label # 0.2 down from x axis\n",
    "        ratio_axes.set_xlabel(labelfile.variable_labels[x_variable],fontname='sans-serif',fontsize=11)\n",
    "        ratio_axes.tick_params(which='both',direction='in',top=True,labeltop=False,right=True,labelright=False)\n",
    "        ratio_axes.set_ylim(bottom=0,top=2.5)\n",
    "        ratio_axes.set_yticks([0,1,2])\n",
    "        ratio_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        if signal is not None:\n",
    "            ratio_axes.set_ylabel(r'Data/SM',fontname='sans-serif',x=1,fontsize=11)\n",
    "        else:\n",
    "            ratio_axes.set_ylabel(r'Data/MC',fontname='sans-serif',fontsize=11)\n",
    "        \n",
    "        \n",
    "        # Generic features for both plots\n",
    "        main_axes.yaxis.set_label_coords(h_y_label_x_position,1)\n",
    "        ratio_axes.yaxis.set_label_coords(h_y_label_x_position,0.5)\n",
    "    \n",
    "        plt.savefig(\"HZZ_\"+x_variable+\".pdf\")\n",
    "    \n",
    "    return signal_x,mc_x_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_yields,background_yields = plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
