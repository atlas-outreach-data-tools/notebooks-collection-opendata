{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"../../images/ATLASOD.gif\" style=\"width:50%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to rediscover the Higgs boson yourself!\n",
    "This notebook uses ATLAS Open Data http://opendata.atlas.cern to show you the steps to rediscover the Higgs boson yourself!\n",
    "\n",
    "The idea is that cuts increase the ratio of signal ($H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$) to background ($Z, t\\bar{t}, ZZ \\rightarrow \\ell\\ell\\ell\\ell$)\n",
    "\n",
    "First, the amount of $Z$ and $t\\bar{t}$ background is reduced, since these are quite different to the signal.\n",
    "\n",
    "Then, the amount of $ZZ \\rightarrow \\ell\\ell\\ell\\ell$ is reduced, whilst keeping $H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$ signal\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 4 leptons per event, so that processing is quicker.\n",
    "\n",
    "This analysis loosely follows the discovery of the Higgs boson by ATLAS https://arxiv.org/pdf/1207.7214.pdf (mostly Section 4 and 4.1)\n",
    "\n",
    "Feynman diagram pictures are borrowed from our friends at https://www.particlezoo.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"HZZ_feynman.png\" style=\"width:40%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time setup on your computer (no need on mybinder)\n",
    "This first cell only needs to be run the first time you open this notebook on your computer. \n",
    "\n",
    "If you close Jupyter and re-open on the same computer, you won't need to run this first cell again.\n",
    "\n",
    "If you open on mybinder, you don't need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --user pip # update the pip package installer\n",
    "!{sys.executable} -m pip install uproot pandas numpy matplotlib --user # install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To setup everytime\n",
    "Cell -> Run All Below\n",
    "\n",
    "to be done every time you re-open this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot # for reading .root files\n",
    "import pandas as pd # to store data as dataframe\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import concurrent.futures # for parallel file reading\n",
    "from matplotlib.ticker import AutoMinorLocator # for minor ticks\n",
    "\n",
    "import infofile # local file containing info on cross-sections, sums of weights, dataset IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General definitions of luminosity, fraction of data used, where to access the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "fraction = 0.9 # reduce this is you want the code to run quicker\n",
    "                                                                                                                                  \n",
    "#tuple_path = \"Input/4lep/\" # local \n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/4lep/\" # web address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samples to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['data_A','data_B','data_C','data_D']\n",
    "    },\n",
    "\n",
    "    r'$Z,t\\bar{t}$' : { # Z + ttbar\n",
    "        'list' : ['Zee','Zmumu','ttbar_lep'],\n",
    "        'color' : \"#6b59d3\" # purple\n",
    "    },\n",
    "\n",
    "    'ZZ' : {\n",
    "        'list' : ['llll'],\n",
    "        'color' : \"#ff0000\" # red\n",
    "    },\n",
    "\n",
    "    r'$H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$' : { # H -> ZZ -> llll\n",
    "        'list' : ['ggH125_ZZ4lep','VBFH125_ZZ4lep','WH125_ZZ4lep','ZH125_ZZ4lep'],\n",
    "        'color' : \"#00cdff\" # light blue\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to get data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    data = {}\n",
    "    for s in samples:\n",
    "        print('Processing '+s+' samples')\n",
    "        frames = []\n",
    "        for val in samples[s]['list']:\n",
    "            prefix = \"MC/mc_\"\n",
    "            if s == 'data':\n",
    "                prefix = \"Data/\"\n",
    "            else: prefix += str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "            fileString = tuple_path+prefix+val+\".4lep.root\"\n",
    "            if fileString != \"\":\n",
    "                temp = read_file(fileString,val)\n",
    "                frames.append(temp)\n",
    "            else:\n",
    "                print(\"Error: \"+val+\" not found!\")\n",
    "        data[s] = pd.concat(frames)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function to calculate weight of MC event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(mcWeight,scaleFactor_PILEUP,scaleFactor_ELE,\n",
    "                scaleFactor_MUON, scaleFactor_LepTRIGGER):\n",
    "    return mcWeight*scaleFactor_PILEUP*scaleFactor_ELE*scaleFactor_MUON*scaleFactor_LepTRIGGER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function to get cross-section weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xsec_weight(totalWeight,sample):\n",
    "    info = infofile.infos[sample]\n",
    "    weight = (lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
    "    weight *= totalWeight\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function to calculate 4-lepton invariant mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mllll(lep_pt,lep_eta,lep_phi,lep_E):\n",
    "    # first lepton is [0], 2nd lepton is [1] etc\n",
    "    px_0 = lep_pt[0]*math.cos(lep_phi[0]) # x-component of lep[0] momentum\n",
    "    py_0 = lep_pt[0]*math.sin(lep_phi[0]) # y-component of lep[0] momentum\n",
    "    pz_0 = lep_pt[0]*math.sinh(lep_eta[0]) # z-component of lep[0] momentum\n",
    "    px_1 = lep_pt[1]*math.cos(lep_phi[1]) # x-component of lep[1] momentum\n",
    "    py_1 = lep_pt[1]*math.sin(lep_phi[1]) # y-component of lep[1] momentum\n",
    "    pz_1 = lep_pt[1]*math.sinh(lep_eta[1]) # z-component of lep[1] momentum\n",
    "    px_2 = lep_pt[2]*math.cos(lep_phi[2]) # x-component of lep[2] momentum\n",
    "    py_2 = lep_pt[2]*math.sin(lep_phi[2]) # y-component of lep[2] momentum\n",
    "    pz_2 = lep_pt[2]*math.sinh(lep_eta[2]) # z-component of lep[3] momentum\n",
    "    px_3 = lep_pt[3]*math.cos(lep_phi[3]) # x-component of lep[3] momentum\n",
    "    py_3 = lep_pt[3]*math.sin(lep_phi[3]) # y-component of lep[3] momentum\n",
    "    pz_3 = lep_pt[3]*math.sinh(lep_eta[3]) # z-component of lep[3] momentum\n",
    "    sumpx = px_0 + px_1 + px_2 + px_3 # x-component of 4-lepton momentum\n",
    "    sumpy = py_0 + py_1 + py_2 + py_3 # y-component of 4-lepton momentum\n",
    "    sumpz = pz_0 + pz_1 + pz_2 + pz_3 # z-component of 4-lepton momentum\n",
    "    sumE = lep_E[0] + lep_E[1] + lep_E[2] + lep_E[3] # energy of 4-lepton system\n",
    "    return math.sqrt(sumE**2 - sumpx**2 - sumpy**2 - sumpz**2)/1000 #/1000 to go from MeV to GeV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing an already uncommented cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you change a cut: Cell -> Run All Below\n",
    "\n",
    "If you uncomment a cut here, you also need to uncomment the corresponding cut in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut on number of leptons\n",
    "# paper: \"selecting two pairs of isolated leptons\"\n",
    "def cut_lep_n(lep_n):\n",
    "# exclamation mark (!) means \"not\"\n",
    "# so != means \"not equal to\"\n",
    "# throw away when number of leptons is not equal to 4 \n",
    "    return lep_n != 4\n",
    "\n",
    "# cut on lepton charge\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_charge(lep_charge):\n",
    "# throw away when sum of lepton charges is not equal to 0\n",
    "# first lepton is [0], 2nd lepton is [1] etc\n",
    "    return lep_charge[0] + lep_charge[1] + lep_charge[2] + lep_charge[3] != 0\n",
    "\n",
    "# cut on lepton type\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_type(lep_type):\n",
    "# for an electron lep_type is 11\n",
    "# for a muon lep_type is 13\n",
    "# throw away when none of eeee, mumumumu, eemumu\n",
    "    sum_lep_type = lep_type[0] + lep_type[1] + lep_type[2] + lep_type[3]\n",
    "    return (sum_lep_type != 44) and (sum_lep_type != 48) and (sum_lep_type != 52)\n",
    "\n",
    "#cut on transverse momentum of the leptons\n",
    "# paper: \" the second (third) lepton in pT order must satisfy pT > 15 GeV (pT > 10 GeV)\"\n",
    "def cut_lep_pt_012(lep_pt):\n",
    "# throw away any events where lep_pt[1] < 15000\n",
    "# throw away any events where lep_pt[2] < 10000\n",
    "    return lep_pt[1] < 15000 or lep_pt[2] < 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncommenting a new cut\n",
    "If you add a cut: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time() # start the clock\n",
    "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
    "    data_all = pd.DataFrame() # define empty pandas DataFrame to hold all data for this sample\n",
    "    mc = uproot.open(path)[\"mini\"] # open the tree called mini\n",
    "    numevents = uproot.numentries(path, \"mini\") # number of events\n",
    "    for data in mc.iterate([\"lep_n\",\"lep_pt\",\"lep_eta\",\"lep_phi\",\"lep_E\",\"lep_charge\",\"lep_type\",\"lep_ptcone30\",\n",
    "                            \"lep_etcone20\", # add more variables here if you make cuts on them \n",
    "                            \"mcWeight\",\"scaleFactor_PILEUP\",\"scaleFactor_ELE\",\"scaleFactor_MUON\",\n",
    "                            \"scaleFactor_LepTRIGGER\"], # variables to calculate Monte Carlo weight\n",
    "                           flatten=False, # make JaggedArrays lists\n",
    "                           entrysteps=2500000, # number of events in a batch to process\n",
    "                           outputtype=pd.DataFrame, # choose output type as pandas DataFrame\n",
    "                           entrystop=numevents*fraction): # process up to numevents*fraction\n",
    "\n",
    "        nIn = len(data.index) # number of events in this batch\n",
    "        print('\\t initial number of events:\\t\\t\\t',nIn)\n",
    "\n",
    "        if 'data' not in sample: # only do this for Monte Carlo simulation files\n",
    "            # multiply all Monte Carlo weights and scale factors together to give total weight\n",
    "            data['totalWeight'] = np.vectorize(calc_weight)(data.mcWeight,data.scaleFactor_PILEUP,\n",
    "                                                            data.scaleFactor_ELE,data.scaleFactor_MUON,\n",
    "                                                            data.scaleFactor_LepTRIGGER)\n",
    "            # incorporate the cross-section weight into the total weight\n",
    "            data['totalWeight'] = np.vectorize(get_xsec_weight)(data.totalWeight,sample)\n",
    "            \n",
    "        # drop the columns we don't need anymore from the dataframe\n",
    "        data.drop([\"mcWeight\",\"scaleFactor_PILEUP\",\"scaleFactor_ELE\",\"scaleFactor_MUON\",\"scaleFactor_LepTRIGGER\"], \n",
    "                  axis=1, inplace=True)\n",
    "\n",
    "        # cut on number of leptons using the function cut_lep_n defined above\n",
    "        fail = data[ np.vectorize(cut_lep_n)(data.lep_n)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after requiring 4 leptons:\\t\\t\\t',len(data.index))\n",
    "\n",
    "        # cut on lepton charge using the function cut_lep_charge defined above\n",
    "        fail = data[ np.vectorize(cut_lep_charge)(data.lep_charge) ].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after requiring zero net charge:\\t\\t',len(data.index))\n",
    "\n",
    "        # cut on lepton type using the function cut_lep_type defined above\n",
    "        fail = data[ np.vectorize(cut_lep_type)(data.lep_type) ].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        print('\\t after requiring lepton pairs of same type:\\t',len(data.index))\n",
    "\n",
    "        #cut on the transverse momentum of the leptons using the function cut_lep_pt_012 defined above\n",
    "        fail =data[ np.vectorize(cut_lep_pt_012)(data.lep_pt)].index\n",
    "        data.drop(fail,inplace=True)\n",
    "        print('\\t after requirements on lepton pt:\\t\\t',len(data.index))\n",
    "\n",
    "        # calculation of 4-lepton invariant mass using the function calc_mllll defined above\n",
    "        data['mllll'] = np.vectorize(calc_mllll)(data.lep_pt,data.lep_eta,data.lep_phi,data.lep_E)\n",
    "\n",
    "        # dataframe contents can be printed at any stage like this\n",
    "        #print(data)\n",
    "\n",
    "        # dataframe column can be printed at any stage like this\n",
    "        #print(data['lep_pt'])\n",
    "\n",
    "        # multiple dataframe columns can be printed at any stage like this\n",
    "        #print(data[['lep_pt','lep_eta']])\n",
    "\n",
    "        nOut = len(data.index) # number of events passing cuts in this batch\n",
    "        data_all = data_all.append(data) # append dataframe from this batch to the dataframe for the whole sample\n",
    "        elapsed = time.time() - start # time taken to process\n",
    "        print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
    "    \n",
    "    return data_all # return dataframe containing events passing all cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the processing happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a change to plotting\n",
    "If you only want a make a change in plotting: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mllll = { # dictionary containing plotting parameters for the mllll histogram\n",
    "    # change plotting parameters\n",
    "    'bin_width':5, # width of each histogram bin\n",
    "    'num_bins':34, # number of histogram bins\n",
    "    'xrange_min':80, # minimum on x-axis\n",
    "    'xlabel':r'$\\mathrm{m_{4l}}$ [GeV]', # x-axis label\n",
    "\n",
    "    # change aesthetic parameters if you want\n",
    "    'y_label_x_position':-0.09, # 0.09 to the left of y axis\n",
    "    'linear_top_margin':1.4 # to decrease the separation between data and the top of the figure, pick a number closer to 1\n",
    "}\n",
    "\n",
    "hist_dict = {'mllll':mllll} # add a histogram here if you want it plotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "\n",
    "    plot_label = r'$H \\rightarrow ZZ^* \\rightarrow \\ell\\ell\\ell\\ell$' # label to write on the plot\n",
    "    signal_label = 'Signal ($m_H=125$ GeV)' # signal label in legend\n",
    "    signal = r'$H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$' # which sample is the signal\n",
    "\n",
    "    # *******************\n",
    "    # general definitions (shouldn't need to change)\n",
    "    lumi_used = str(lumi*fraction) # luminosity to write on the plot\n",
    "\n",
    "    for x_variable,hist in hist_dict.items(): # access the dictionary of histograms defined in the cell above\n",
    "\n",
    "        h_bin_width = hist['bin_width'] # get the bin width defined in the cell above\n",
    "        h_num_bins = hist['num_bins'] # get the number of bins defined in the cell above\n",
    "        h_xrange_min = hist['xrange_min'] # get the x-range minimum defined in the cell above\n",
    "        h_xlabel = hist['xlabel'] # get the x-axis label defined in the cell above\n",
    "        h_y_label_x_position = hist['y_label_x_position'] # get the x-position of the y-axis label defined in the cell above\n",
    "        h_linear_top_margin = hist['linear_top_margin'] # to decrease the separation between data and the top of the figure, pick a number closer to 1\n",
    "    \n",
    "        bins = [ h_xrange_min + x*h_bin_width for x in range(h_num_bins+1) ] # bin limits\n",
    "        bin_centres = [ h_xrange_min+h_bin_width/2 + x*h_bin_width for x in range(h_num_bins) ] # bin centres\n",
    "\n",
    "        data_x,_ = np.histogram( data['data'][x_variable].values, bins=bins ) # histogram the data\n",
    "        data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "\n",
    "        signal_x = data[signal][x_variable].values # histogram the signal\n",
    "        signal_weights = data[signal].totalWeight.values # get the weights of the signal events\n",
    "        signal_color = samples[signal]['color'] # get the colour for the signal bar\n",
    "    \n",
    "        mc_x = [] # define list to hold the Monte Carlo histogram entries\n",
    "        mc_weights = [] # define list to hold the Monte Carlo weights\n",
    "        mc_colors = [] # define list to hold the colors of the Monte Carlo bars\n",
    "        mc_labels = [] # define list to hold the legend labels of the Monte Carlo bars\n",
    "        mc_x_tot = np.zeros( len(bin_centres) ) # define array of length bin_centres to hold the sum of MC bars\n",
    "\n",
    "        for s in samples: # loop over samples\n",
    "            if s not in ['data', signal]: # if not data nor signal\n",
    "                mc_x.append( data[s][x_variable].values ) # append to the list of Monte Carlo histogram entries\n",
    "                mc_weights.append( data[s].totalWeight.values ) # append to the list of Monte Carlo weights\n",
    "                mc_colors.append( samples[s]['color'] ) # append to the list of Monte Carlo bar colors\n",
    "                mc_labels.append( s ) # append to the list of Monte Carlo legend labels\n",
    "                mc_x_heights,_ = np.histogram(data[s][x_variable].values, bins=bins,\n",
    "                                              weights=data[s].totalWeight.values ) # histogram the current sample\n",
    "                mc_x_tot = np.add( mc_x_tot, mc_x_heights ) # add to the array holding the total MC y-axis value\n",
    "    \n",
    "        mc_x_err = np.sqrt( mc_x_tot ) # statistical error on the Monte Carlo bars\n",
    "    \n",
    "    \n",
    "        # *************\n",
    "        # Main plot \n",
    "        # *************\n",
    "        plt.clf() # clear figure\n",
    "        plt.axes([0.1,0.3,0.85,0.65]) # left, bottom, width, height\n",
    "        main_axes = plt.gca() # get current axes\n",
    "        # plot the data points\n",
    "        main_axes.errorbar( x=bin_centres, y=data_x, yerr=data_x_errors, fmt='ko', label='Data' ) \n",
    "        # plot the Monte Carlo bars\n",
    "        mc_heights = main_axes.hist(mc_x, bins=bins, weights=mc_weights, stacked=True, color=mc_colors, \n",
    "                                    label=mc_labels )\n",
    "        # plot the signal bar\n",
    "        main_axes.hist(signal_x, bins=bins, bottom=mc_x_tot, weights=signal_weights, color=signal_color,\n",
    "                       label=signal )\n",
    "        # plot the statistical uncertainty\n",
    "        main_axes.bar(bin_centres, # x\n",
    "                      2*mc_x_err, # heights\n",
    "                      alpha=0.5, # half transparency\n",
    "                      bottom=mc_x_tot-mc_x_err, color='none', hatch=\"////\", width=h_bin_width, \n",
    "                      label='Stat. Unc.' )\n",
    "        \n",
    "        main_axes.set_xlim( left=h_xrange_min, right=bins[-1] ) # set the x-limit of the main axes\n",
    "        main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) # separation of x axis minor ticks\n",
    "        # set the axis tick parameters for the main axes\n",
    "        main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                              direction='in', # Put ticks inside and outside the axes\n",
    "                              top=True, # draw ticks on the top axis\n",
    "                              labeltop=False, # don't draw tick labels on top axis\n",
    "                              labelbottom=False, # don't draw tick labels on bottom axis\n",
    "                              right=True, # draw ticks on right axis\n",
    "                              labelright=False ) # don't draw tick labels on right axis\n",
    "        if len( h_xlabel.split('[') ) > 1: # if x-axis has units\n",
    "            y_units = ' '+h_xlabel[h_xlabel.find(\"[\")+1:h_xlabel.find(\"]\")]\n",
    "        else: y_units = '' # if x-axis is unitless\n",
    "        main_axes.set_ylabel('Events / '+str(h_bin_width)+y_units, fontname='sans-serif',\n",
    "                             horizontalalignment='right', y=1.0, fontsize=11 ) # write y-axis label for main axes\n",
    "        # set y-axis limits for main axes\n",
    "        main_axes.set_ylim( bottom=0, top=(np.amax(data_x)+math.sqrt(np.amax(data_x)))*h_linear_top_margin )\n",
    "        main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) # add minor ticks on y-axis for main axes\n",
    "        \n",
    "        # Add text 'ATLAS Open Data' on plot\n",
    "        plt.text(0.05, # x\n",
    "                 0.97, # y\n",
    "                 'ATLAS Open Data', # text\n",
    "                 transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "                 horizontalalignment='left', verticalalignment='top', family='sans-serif', fontsize=13 ) \n",
    "        # Add text 'for education' on plot\n",
    "        plt.text(0.05, # x\n",
    "                 0.9, # y\n",
    "                 'for education', # text\n",
    "                 transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "                 horizontalalignment='left', verticalalignment='top', family='sans-serif', style='italic',\n",
    "                 fontsize=8 ) \n",
    "        # Add energy and luminosity\n",
    "        plt.text(0.05, # x\n",
    "                 0.86, # y\n",
    "                 '$\\sqrt{s}=13\\,\\mathrm{TeV},\\;\\int L\\,dt=$'+lumi_used+'$\\,\\mathrm{fb}^{-1}$', # text\n",
    "                 transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "                 horizontalalignment='left', verticalalignment='top', family='sans-serif' ) \n",
    "        # Add a label for the analysis carried out\n",
    "        plt.text(0.05, # x\n",
    "                 0.78, # y\n",
    "                 plot_label, # text \n",
    "                 transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "                 horizontalalignment='left', verticalalignment='top', family='sans-serif' )\n",
    "    \n",
    "        # Create new legend handles but use the colors from the existing ones \n",
    "        handles, labels = main_axes.get_legend_handles_labels()\n",
    "    \n",
    "        # specify order within legend\n",
    "        new_handles = [ handles[labels.index('Data')] ] # first entry in legend is 'Data'\n",
    "        new_labels = ['Data']\n",
    "        for s in reversed( list( samples.keys() ) ): # loop over samples names\n",
    "            if s not in ['data', signal]: # if not data nor signal\n",
    "                new_handles.append( handles[labels.index(s)] ) # next entries in legend are the Background MC\n",
    "                new_labels.append( s )\n",
    "        new_handles.append( handles[labels.index(signal)] ) # next entry in legend is signal\n",
    "        new_labels.append( signal_label )\n",
    "        new_handles.append( handles[labels.index('Stat. Unc.')] ) # next entry in legend is uncertainty\n",
    "        new_labels.append( 'Stat. Unc.' )\n",
    "        \n",
    "        # draw the legend\n",
    "        main_axes.legend( handles=new_handles, labels=new_labels, frameon=False ) # no box around the legend\n",
    "    \n",
    "    \n",
    "        # *************\n",
    "        # Data/MC ratio \n",
    "        # *************\n",
    "        plt.axes([0.1,0.1,0.85,0.2]) # left, bottom, width, height\n",
    "        ratio_axes = plt.gca() # get current axes\n",
    "        ratio_axes.errorbar( x=bin_centres, y=data_x/mc_x_tot, yerr=data_x_errors/mc_x_tot, fmt='ko' )\n",
    "        # draw uncertainty band on ratio axes\n",
    "        ratio_axes.bar(bin_centres, # x\n",
    "                       2*mc_x_err/mc_x_tot, # heights \n",
    "                       alpha=0.5, # half transparency\n",
    "                       bottom=1-mc_x_err/mc_x_tot, color='none', hatch=\"////\", width=h_bin_width )\n",
    "        # draw horizontal line for Data/MC = 1\n",
    "        ratio_axes.plot(bins, # x\n",
    "                        np.ones(len(bins)), # y\n",
    "                        color='k') # 'k' means black\n",
    "        ratio_axes.set_xlim( left=h_xrange_min, right=bins[-1] ) # set the x-axis limits on the ratio axes\n",
    "        ratio_axes.xaxis.set_minor_locator( AutoMinorLocator() ) # separation of x-axis minor ticks\n",
    "        ratio_axes.xaxis.set_label_coords(0.9,-0.2) # (x,y) of x axis label # 0.2 down from x-axis\n",
    "        ratio_axes.set_xlabel( h_xlabel, fontname='sans-serif', fontsize=11) # x-axis label\n",
    "        # set the tick parameters for the ratio axes\n",
    "        sub_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                             direction='in', # Put ticks inside and outside the axes\n",
    "                             top=True, # draw ticks on the top axis\n",
    "                             labeltop=False, # don't draw tick labels on top axis\n",
    "                             right=True, # draw ticks on right axis\n",
    "                             labelright=False ) # don't draw tick labels on right axis\n",
    "        ratio_axes.set_ylim( bottom=0, top=2.5 ) # set the y-axis limits on the ratio axes\n",
    "        ratio_axes.set_yticks( [0,1,2] ) # set the values to be labelled on the y-axis\n",
    "        ratio_axes.yaxis.set_minor_locator( AutoMinorLocator() ) # separation of x-axis minor ticks\n",
    "        ratio_axes.set_ylabel( 'Data/SM', fontname='sans-serif', x=1, fontsize=11 ) # y-axis label on the ratio axes\n",
    "        \n",
    "        \n",
    "        # Generic features for both plots\n",
    "        main_axes.yaxis.set_label_coords( h_y_label_x_position, 1 ) # x,y coordinates of the y-axis label on the main axes\n",
    "        ratio_axes.yaxis.set_label_coords( h_y_label_x_position, 0.5 ) # x,y coordinates of the y-axis label on the ratio axes\n",
    "    \n",
    "        plt.savefig( \"HZZ_\"+x_variable+\".pdf\", bbox_inches='tight' ) # save the plot\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
