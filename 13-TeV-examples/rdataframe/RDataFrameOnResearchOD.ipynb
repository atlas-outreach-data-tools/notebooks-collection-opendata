{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzhF1LLDvoJw"
   },
   "source": [
    "# Analyse Research Open Data with ROOT's RDataFrame\n",
    "\n",
    "This note book will show you how to build up an analysis on the Research Open Data using ROOT's RDataFrame. RDataFrame offers a modern, high-level interface for analysis of data stored in TTree, CSV and other data formats, in C++ or Python.\n",
    "\n",
    "In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available on their machines completely transparently.\n",
    "\n",
    "RDataFrame allows you to interact with the Reserach Open Data in a \"columnar style\" way. Calculations are expressed in terms of actions and transformations, RDataFrame takes care of their execution. The implementation automatically puts in place several low level optimisations such as multi-thread parallelization and caching.\n",
    "\n",
    "Let's start by getting ROOT installed in your environment. The exact procedure will depend on where you run your framework. If you use Google Colab or Swan you should set the appropriate variable to True below and ROOT will be setup correctly.\n",
    "\n",
    "If you're working on your own machine is relatively simple to install ROOT, please look at the [documentation pages](https://root.cern.ch/install/).\n",
    "\n",
    "There's lot's of useful documentation on RDataFrames [here](https://root.cern/doc/master/classROOT_1_1RDataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsedwKC9ssha"
   },
   "outputs": [],
   "source": [
    "isSwan = False\n",
    "isColab = True\n",
    "isBinder = False\n",
    "isGalaxy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiTvsaL7xwkG"
   },
   "source": [
    "Continue to the setup. This may take some time depending on your internet connection, as a few files will need to be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doDKLG6cHHxW",
    "outputId": "4748f03b-53be-42fa-beaf-22f8baa4f9e7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if isColab:\n",
    "    if not os.path.exists(\"/content/root_build\"):\n",
    "        if not os.path.exists(\"/content/root_v6.32.04_Ubuntu_Python3.12.zip\"):\n",
    "            !wget -q --show-progress https://github.com/MohamedElashri/ROOT/releases/download/root-v6.32.04-python3.12/root_v6.32.04_Ubuntu_Python3.12.zip\n",
    "        !unzip -q /content/root_v6.32.04_Ubuntu_Python3.12.zip\n",
    "    !wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
    "    !sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
    "    !rm -f libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
    "    !sudo apt install xrootd-client xrootd-server python3-xrootd\n",
    "    import sys\n",
    "    import ctypes\n",
    "\n",
    "    # Step 1: Append ROOT paths to Python\n",
    "    sys.path.append(\"root_build/\")\n",
    "    sys.path.append(\"root_build/bin/\")\n",
    "    sys.path.append(\"root_build/include/\")\n",
    "    sys.path.append(\"root_build/lib/\")\n",
    "\n",
    "    # Step 2: Load the required shared libraries (.so files)\n",
    "    ctypes.cdll.LoadLibrary(\"root_build/lib/libCore.so\")\n",
    "    ctypes.cdll.LoadLibrary(\"root_build/lib/libThread.so\")\n",
    "    ctypes.cdll.LoadLibrary(\"root_build/lib/libTreePlayer.so\")\n",
    "\n",
    "    print(\"ROOT Libraries Loaded Successfully!\")\n",
    "elif isSwan:\n",
    "    print(\"INFO \\t Nothing to be done. ROOT's already installed!\")\n",
    "elif isBinder:\n",
    "    print(\"ERROR \\t Running the notebook in Binder is not yet supported\")\n",
    "else:\n",
    "    print(\"ERROR \\t Please specify your environment (Swan or Google Colab) or create your own setup...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qb2Tani1tt8Y",
    "outputId": "dffd2d6b-746a-4aac-f00e-a1aa5eb6e460"
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "print(f\"ROOT Version: {ROOT.gROOT.GetVersion()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILlqjlidtChV"
   },
   "outputs": [],
   "source": [
    "# Tip: If you'd like to mount your drive in google (e.g. to store the root distribution for next time)\n",
    "# you can do so here. This would mean that you don't have to download the root distribution\n",
    "# file every time, but you can rather get it from your google drive (which is not deleted after some certain amount of time.)\n",
    "# Load the Drive helper and mount\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYv5lygRIDHR",
    "outputId": "952f8b7d-6146-44a9-a1c7-dc3771942d0d"
   },
   "outputs": [],
   "source": [
    "# First we install atlasopenmagic into our SWAN environment\n",
    "# Notice that we need --user to avoid trying to install the package in a\n",
    "# read-only file system This is a problem unique to SWAN; on binder or colab you\n",
    "# won't need --user, but it doesn't hurt\n",
    "%pip install --user atlasopenmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLdG48J2q2eT"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Now we have to do a little bit of work to make sure that atlasopenmagic is\n",
    "# available in our python path This is because SWAN by default does not include\n",
    "# the local package installation area in the PYTHONPATH Again, this is not\n",
    "# necessary on binder or colab - there you can remove these lines if you like,\n",
    "# though they don't do any harm\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "sys.path += [ f'{os.environ[\"HOME\"]}/.local/lib/python{sys.version_info.major}.{sys.version_info.minor}/site-packages' ]\n",
    "\n",
    "import atlasopenmagic as atom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQV6ArqYyisn"
   },
   "source": [
    "## Simple Introduction\n",
    "\n",
    "We will start by loading one file from the Research Open Data release. You specify the name of the TTree (`CollectionTree` for all files in the OD for research release) and the filename.\n",
    "\n",
    "This will throw a bunch of Wanring messages as there are several of the branches we can not read in the PHYSLITE files (need ATLAS software). But we can ignore this for now as we are not gonna use any of those branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZkXxWb0dFkB",
    "outputId": "29ebcc74-a517-49f1-d7f1-38b8af4ce5c6"
   },
   "outputs": [],
   "source": [
    "# Large file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.37110937._000011.pool.root.1\n",
    "# Small file: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000001.pool.root.1\n",
    "df = ROOT.RDataFrame(\"CollectionTree\",\"root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000001.pool.root.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.Define(\"photon_isTightID\",\"AnalysisPhotonsAuxDyn.DFCommonPhotonsIsEMTight\")\n",
    "df = df.Filter('ROOT::VecOps::Sum(photon_isTightID)>=2',\"Two tight photons\")\n",
    "df = df.Define(\"photon_pt\",\"AnalysisPhotonsAuxDyn.pt/1000.\")\n",
    "df = df.Filter(\"Sum(photon_pt>50)>0 && Sum(photon_pt>30)>1\",\"Pt > 50, 30 GeV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Report().Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.Define(\"photon_pt[photon_isTightID]\",\"AnalysisPhotonsAuxDyn.pt/1000.\")\n",
    "histogram = df.Histo1D((\"h_pt\",\"Invariant mass of two photons;m_{ee} [GeV];Events\",100,0,200),\"photon_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ROOT.TCanvas()\n",
    "c.Draw()\n",
    "histogram.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqGWnQm2zkus"
   },
   "source": [
    "Most actions in RDataFrame are **lazy**, i.e. they are not executed on the spot, but registered with RDataFrame and executed only when a result is accessed for the first time.\n",
    "\n",
    "One example of a lazy action is the Count() function, returning the number of events loaded in our RDF. This means that the following command does nothing (except for making a pointer object to the results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWtPDtlYecFp"
   },
   "outputs": [],
   "source": [
    "ptr = df.Count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xg_A8MBz5ve"
   },
   "source": [
    "When we explicitely ask to get the number of events the execution is launched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfRni9mnuWzx",
    "outputId": "68874259-df7a-4775-efeb-75863ea9797d"
   },
   "outputs": [],
   "source": [
    "ptr.GetValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26hrfnci0XdC"
   },
   "source": [
    "We can also look at the content of the TTree in RDF. This function does not modify the dataframe or book computations, but simply return information on the RDataFrame object.\n",
    "\n",
    "Note that the only branches we can actually read in RDF are the ones with `AuxDyn` in the name so let's just print those.\n",
    "\n",
    "If you're not familiar with the content of the PHYSLITE files you should consider looking through the following notebook: [Using the PHYSLITE format](https://opendata.atlas.cern/docs/tutresearch/physlitetut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfdzvDWy6c0n",
    "outputId": "1d84592e-ea9d-4b83-d68e-b379ce6d914b"
   },
   "outputs": [],
   "source": [
    "# Get list of readable branches\n",
    "# The list auxDyn will contain all the name and data type of all readable branches\n",
    "auxDyn = []\n",
    "for name in df.GetColumnNames():\n",
    "  if \"AuxDyn\" in str(name):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLxKLUZK1cA4"
   },
   "source": [
    "## A first simple analysis\n",
    "\n",
    "Let's start with defining some new variables, make some selections and make a histogram.\n",
    "\n",
    "We start by defining \"good\" electrons with some basic $p_T$, $\\eta$ and quality requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BqtC3CaAXd-"
   },
   "outputs": [],
   "source": [
    "# Use Define to create new variables from existing ones\n",
    "df = df.Define(\"signal_el\",\"AnalysisElectronsAuxDyn.eta > -2.47 && \\\n",
    "                            AnalysisElectronsAuxDyn.eta <  2.47 && \\\n",
    "                            AnalysisElectronsAuxDyn.pt > 7000 && \\\n",
    "                            AnalysisElectronsAuxDyn.DFCommonElectronsLHTight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Xi8vMsKBCLO"
   },
   "outputs": [],
   "source": [
    "# Count the number of good electrons in each event\n",
    "df = df.Define('n_signal_el','ROOT::VecOps::Sum(signal_el)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPhE8-AVBaSN"
   },
   "outputs": [],
   "source": [
    "# Requre at least two good electrons in every event\n",
    "df = df.Filter('n_signal_el >= 2',\"At least two good electrons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmDjgEDq2U4U"
   },
   "source": [
    "RDataFrame comes with a function to present an overview of the number of events passing each selection crieria (specified by the Filter()-command). Above we only added one selection, but let's see how many events passed the selection.\n",
    "\n",
    "Report() is also lazy so nothing gets executed if you don't call Print()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwHAhNdOBnNX",
    "outputId": "ebd1b816-0579-4561-bce8-8f4d0790e4d1"
   },
   "outputs": [],
   "source": [
    "df.Report().Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSOnxFPG3Bd_"
   },
   "source": [
    "### Using C++ function in RDataFrame\n",
    "\n",
    "One thing which is very useful in RDF and ROOT is to use C++ functions from python. In Colab we need to make sure the PATH's are set so that the system finds the ROOT Cling compiler.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2l8VFu-KH-6"
   },
   "outputs": [],
   "source": [
    "os.environ['ROOTSYS'] = '/content/root_build'\n",
    "os.environ['PATH'] += ':/content/root_build/bin'\n",
    "os.environ['LD_LIBRARY_PATH'] += ':/content/root_build/lib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8L7S3qI3mns"
   },
   "source": [
    "Then we can define a C++ function within the `ROOT.gInterpreter.Declare` and it will be compile immediately. It can take as input any of the variables available in our dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlfhCaHqCFvf",
    "outputId": "023bbf6c-546a-4da4-baad-330d57374e28"
   },
   "outputs": [],
   "source": [
    "# Define the function to calculate invariant mass of 2 and 4 leptons\n",
    "ROOT.gInterpreter.Declare(\n",
    "    \"\"\"\n",
    "#include <TMath.h>\n",
    "using VecF_t = const ROOT::RVec<float>&;\n",
    "float ComputeInvariantMass(VecF_t& pt, VecF_t& eta, VecF_t& phi)\n",
    "{\n",
    "  if(int(pt.size())<2)return -999;\n",
    "  ROOT::Math::PtEtaPhiMVector p1(pt[0], eta[0], phi[0], 0.511);\n",
    "  ROOT::Math::PtEtaPhiMVector p2(pt[1], eta[1], phi[1], 0.511);\n",
    "  return (p1 + p2).M()/1000.;\n",
    "};\n",
    "\n",
    "float ComputeInvariantMass4E(VecF_t& pt, VecF_t& eta, VecF_t& phi)\n",
    "{\n",
    "  if(int(pt.size())<4)return -999;\n",
    "  ROOT::Math::PtEtaPhiMVector p1(pt[0], eta[0], phi[0], 0.511);\n",
    "  ROOT::Math::PtEtaPhiMVector p2(pt[1], eta[1], phi[1], 0.511);\n",
    "  ROOT::Math::PtEtaPhiMVector p3(pt[2], eta[2], phi[2], 0.511);\n",
    "  ROOT::Math::PtEtaPhiMVector p4(pt[3], eta[3], phi[3], 0.511);\n",
    "  return (p1 + p2 + p3 + p4).M()/1000.;\n",
    "};\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c96UKXAT37YG"
   },
   "source": [
    "We can now call on the C++ function in Python to create a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONVKqw6DEF13"
   },
   "outputs": [],
   "source": [
    "df = df.Define('mee','ComputeInvariantMass(AnalysisElectronsAuxDyn.pt[signal_el],\\\n",
    "                                           AnalysisElectronsAuxDyn.eta[signal_el],\\\n",
    "                                           AnalysisElectronsAuxDyn.phi[signal_el])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qMIvvLKGDkA",
    "outputId": "c63e5892-f4ca-4e6d-8e05-129a79ef97da"
   },
   "outputs": [],
   "source": [
    "# We can display the first 5 entries of the newly\n",
    "# created variable mee (again, it is lazy so Print()\n",
    "# is needed).\n",
    "df.Display([\"mee\"]).Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXXHCLiA4S1y"
   },
   "source": [
    "RDF comes with functions to define histograms (see [TH1 documentation](https://root.cern.ch/doc/v636/classTH1.html)). Let's create a histogram with the invariant mass of the two electrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROvkvyJiFFHf"
   },
   "outputs": [],
   "source": [
    "# lazy, nothing is done until we use the histogram\n",
    "histogram = df.Histo1D((\"h_mee\",\"Invariant mass of two electrons;m_{ee} [GeV];Events\",100,0,200),\"mee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517,
     "resources": {
      "http://localhost:8080/static/build/jsroot.js": {
       "data": "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",
       "headers": [
        [
         "content-length",
         "2954"
        ],
        [
         "content-type",
         "text/html"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "QgEIkgVNFjVv",
    "outputId": "77951de5-540d-499e-9beb-d9ce5cee83ea"
   },
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "c = ROOT.TCanvas(\"c\",\"c\",1)\n",
    "c.Draw()\n",
    "# This would trigger the execution\n",
    "histogram.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-6ZrZe_5O5D"
   },
   "source": [
    "## A more complete analysis in RDF\n",
    "\n",
    "Let's move to a slightly more complete analysis using RDataFrame and Research Open Data. To get hold of the data and corresponding metadata we will use `atlasopenmagic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Stf-v7bpMBY",
    "outputId": "ca6c928e-692b-457b-ec4b-d8210780e8d5"
   },
   "outputs": [],
   "source": [
    "atom.available_releases()\n",
    "# Set the release to the Research Open Data release\n",
    "# If access to /eos/ (e.g. in some instances of Swan) \n",
    "# files can be accessed directly from there. If not we need\n",
    "# to use https/root protocol and cache them (see next cell)\n",
    "if os.path.exists(\"/eos/opendata\"):\n",
    "    atom.set_release('2024r-pp',local_path=\"eos\")\n",
    "else:\n",
    "    atom.set_release('2024r-pp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WqgepQTmy8W"
   },
   "outputs": [],
   "source": [
    "# Define the input data sets we'd like to use (a selection of samples used for the H->ZZ analysis)\n",
    "# Unfortunately Google Colab is too slow so in interest of time let's only look at one smaller Higgs sample\n",
    "if isColab:\n",
    "    defs = {\n",
    "        'Higgs':  {'dids': [345060],'color': \"#00cdff\" },# light blue\n",
    "    }\n",
    "else:\n",
    "    defs = {\n",
    "        'Zjets' :{'dids': [700320,700321,700322], 'color': \"#6b59d3\" },\n",
    "        'ZZ':     {'dids': [700600],'color': \"#ff0000\" },# red\n",
    "        'Higgs':  {'dids': [345060, 346228, 346310],'color': \"#00cdff\" },# light blue\n",
    "        'Data':{'dids':['data']}\n",
    "    }\n",
    "\n",
    "# In swan we can access the samples directly from /eos/ while in colab we must use the root (or https) protocols\n",
    "samples   = atom.build_dataset(defs, protocol='root' if isColab else 'eos', cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7UK7FHf6Hww"
   },
   "source": [
    "When we later are gonna parallelize our execution it is beneficial to put all the files we want to process into one big RDataFrame\n",
    "\n",
    "Remember that we will not have any memory issues doing this since ROOT is handling memory in a completely different way than e.g. is done in Pandas dataframe\n",
    "\n",
    "However, we still need to know which process (real data, simulated ttbar, simulated diboson etc.) each file belongs to when we later want to plot histograms etc. We achieve this by loading the RDataFrame using a specification file in json format (see [documentation](https://root.cern/doc/v632/classROOT_1_1RDataFrame.html)).\n",
    "\n",
    "We would also need to store some of the metadata used to scale the simulations to data.\n",
    "\n",
    "We start by creating the json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uwL99spl6pL",
    "outputId": "1b4dafed-9992-4282-936a-7302677eede2"
   },
   "outputs": [],
   "source": [
    "# Name of the json file.\n",
    "outfilename = \"./spec.json\"\n",
    "# Outermost key must be \"samples\"\n",
    "RDF_spec = {\"samples\":{}}\n",
    "# loping over the samples defined above\n",
    "for name, info in defs.items():\n",
    "    for did in info[\"dids\"]:\n",
    "        if not \"Data\" in name:\n",
    "            # Get the metadata from atom\n",
    "            metadata = {'xsec':atom.get_metadata(did,'cross_section_pb'),\n",
    "                    'sumOfWeights':atom.get_metadata(did,'sumOfWeights'),\n",
    "                    'genFiltEff':atom.get_metadata(did,'genFiltEff'),\n",
    "                    'kFactor':atom.get_metadata(did,'kFactor'),\n",
    "                    'proc':name}\n",
    "            # Populates the dictionary with input samples and metadata\n",
    "            RDF_spec['samples'][did] = {\"trees\":[\"CollectionTree\"],\n",
    "                                        \"files\":[item.replace(\"simplecache::\", \"\") for item in atom.get_urls(str(did), protocol='root', cache=True)],\n",
    "                                        \"metadata\":metadata}\n",
    "        else:\n",
    "            # In interest of time we only look at one run in data (i.e. onlt files with id 37020379 in name)\n",
    "            inputlist = [item.replace(\"simplecache::\", \"\") for item in atom.get_urls(str(did), protocol='root', cache=True) if '37020379' in item]\n",
    "            # metadata is simple for data\n",
    "            metadata = {'xsec':1.0,\n",
    "                    'sumOfWeights':1.0,\n",
    "                    'genFiltEff':1.0,\n",
    "                    'kFactor':1.0,\n",
    "                    'proc':name}\n",
    "            # Populates the dictionary with input samples and metadata\n",
    "            RDF_spec['samples'][did] = {\"trees\":[\"CollectionTree\"], \"files\":inputlist, \"metadata\":metadata}\n",
    "# Save the dictionary to json file\n",
    "with open(outfilename, \"w\") as f:\n",
    "    json.dump(RDF_spec,f)\n",
    "print(\"Created json file %s\\nCan now be loaded into a RDataFrame using:\\ndf = ROOT.RDF.Experimental.FromSpec(\\\"spec.json\\\")\"%outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5N5GAMhTElZ",
    "outputId": "576c7901-b880-4612-c24d-d96e907ebea6"
   },
   "outputs": [],
   "source": [
    "! lscpu | grep 'CPU(s):'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLgbz4DRTJrk"
   },
   "outputs": [],
   "source": [
    "ROOT.EnableImplicitMT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHelq79YnjIX"
   },
   "outputs": [],
   "source": [
    "df = ROOT.RDF.Experimental.FromSpec(\"spec.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f00ZQX0Xg-Y3",
    "outputId": "992cf32e-c652-425d-d672-73e409e5ef03"
   },
   "outputs": [],
   "source": [
    "# Get category\n",
    "df = df.DefinePerSample(\"isData\",f'rdfsampleinfo_.Contains(\"mc20_13TeV\") ? 0 : 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7N4-9HigUjnZ"
   },
   "outputs": [],
   "source": [
    "# Get category\n",
    "df = df.DefinePerSample(\"category\",'rdfsampleinfo_.GetS(\"proc\")')\n",
    "# Get cross-section\n",
    "df = df.DefinePerSample(\"xsec\",'rdfsampleinfo_.GetD(\"xsec\")')\n",
    "# Get sum of event weights\n",
    "df = df.DefinePerSample(\"sow\",'rdfsampleinfo_.GetD(\"sumOfWeights\")')\n",
    "# Get generator filter efficiency\n",
    "df = df.DefinePerSample(\"eff\",'rdfsampleinfo_.GetD(\"genFiltEff\")')\n",
    "# Get k-factor\n",
    "df = df.DefinePerSample(\"kfac\",'rdfsampleinfo_.GetD(\"kFactor\")')\n",
    "# Set the luminoisty of the data set (run 311481) you've added (36.1e3 if you have loaded everything)\n",
    "df = df.DefinePerSample(\"lumi\",'343.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IL8h5RTW0wF"
   },
   "outputs": [],
   "source": [
    "# Calculate the weight to be applied to every event (for data it is simply 1)\n",
    "wgtstr = f'isData ? 1.0 : ((lumi*xsec*kfac*eff)/sow)*EventInfoAuxDyn.mcEventWeights.at(0)'\n",
    "df = df.Define(\"wgt\",wgtstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUcd2CZPUgBY"
   },
   "outputs": [],
   "source": [
    "# Define signal electrons\n",
    "df = df.Define(\"signal_el\",\"AnalysisElectronsAuxDyn.eta > -2.47 && \\\n",
    "                            AnalysisElectronsAuxDyn.eta <  2.47 && \\\n",
    "                            AnalysisElectronsAuxDyn.pt > 7000 && \\\n",
    "                            AnalysisElectronsAuxDyn.DFCommonElectronsLHLoose\")\n",
    "# Make a new variable with the number of signal electrons per event\n",
    "df = df.Define('n_signal_el','ROOT::VecOps::Sum(signal_el)')\n",
    "# Only select events with at leas four signal electrons\n",
    "df = df.Filter('n_signal_el >= 4',\"At least four electrons passing cuts\")\n",
    "# Calculate the invariant mass of those four electrons\n",
    "df = df.Define('m4e','ComputeInvariantMass4E(AnalysisElectronsAuxDyn.pt[signal_el],\\\n",
    "                                           AnalysisElectronsAuxDyn.eta[signal_el],\\\n",
    "                                           AnalysisElectronsAuxDyn.phi[signal_el])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSiSpYKlUgBg"
   },
   "outputs": [],
   "source": [
    "all_histograms = []\n",
    "histograms = {}\n",
    "for proc in defs.keys():\n",
    "  histograms[proc] = df.Filter(f'category == \"{proc}\"').Histo1D((\"h_m4e_%s\"%proc,\"Invariant mass of 4 electrons;m_{4e} [GeV];Events\",50,0,1000),\"m4e\",\"wgt\")\n",
    "  all_histograms.append(histograms[proc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unxDAdN5jX8P",
    "outputId": "1755c889-8774-4b51-9bd6-67f9bf1c515a"
   },
   "outputs": [],
   "source": [
    "ROOT.RDF.RunGraphs(all_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEJdc-jsE4v9",
    "outputId": "02ec2009-7c31-47e1-c34a-f770af708f99"
   },
   "outputs": [],
   "source": [
    "hstack = ROOT.THStack()\n",
    "legend = ROOT.TLegend(0.6,0.7,0.9,0.9)\n",
    "for proc in defs.keys():\n",
    "    print(\"Integral %s : %f\"%(proc,histograms[proc].Integral(0,histograms[proc].GetNbinsX()+1)))\n",
    "    if not \"Data\" in proc:\n",
    "        histograms[proc].SetLineColor(ROOT.TColor.GetColor(defs[proc]['color']))\n",
    "        histograms[proc].SetFillColor(ROOT.TColor.GetColor(defs[proc]['color']))\n",
    "        hstack.Add(histograms[proc].GetValue())\n",
    "        legend.AddEntry(histograms[proc].GetValue(),proc,\"lf\")\n",
    "    else:\n",
    "        histograms[proc].SetMarkerColor(ROOT.kBlack)\n",
    "        histograms[proc].SetLineColor(ROOT.kBlack)\n",
    "        histograms[proc].SetMarkerStyle(20)\n",
    "        legend.AddEntry(histograms[proc].GetValue(),proc,\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534,
     "resources": {
      "http://localhost:8080/static/build/jsroot.js": {
       "data": "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",
       "headers": [
        [
         "content-length",
         "2954"
        ],
        [
         "content-type",
         "text/html"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "o7hjDw-wFp8n",
    "outputId": "d8d9ff8f-60ad-4076-e70d-d0a866ce91a6"
   },
   "outputs": [],
   "source": [
    "#%jsroot on\n",
    "c = ROOT.TCanvas(\"c\",\"c\",1)\n",
    "c.Draw()\n",
    "hstack.Draw(\"hist\")\n",
    "hstack.GetXaxis().SetTitle(\"m_{4e} [GeV]\")\n",
    "hstack.GetYaxis().SetTitle(\"Entries\")\n",
    "hstack.SetMaximum(25)\n",
    "if \"Data\" in histograms.keys():\n",
    "    histograms[\"Data\"].Draw(\"ep same\")\n",
    "legend.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWV3BKiEnaXO"
   },
   "source": [
    "## Convert from ROOT to NumPy\n",
    "\n",
    "You can easilly convert your RDataFrame into NumPy arrays and Pandas data frames.\n",
    "\n",
    "Let's first define some simple variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oEOJ9Vm5N89"
   },
   "outputs": [],
   "source": [
    "df = df.Define(\"lep1_pt\",\"AnalysisElectronsAuxDyn.pt[signal_el].at(0)\")\n",
    "df = df.Define(\"lep2_pt\",\"AnalysisElectronsAuxDyn.pt[signal_el].at(1)\")\n",
    "df = df.Define(\"lep3_pt\",\"AnalysisElectronsAuxDyn.pt[signal_el].at(2)\")\n",
    "df = df.Define(\"lep4_pt\",\"AnalysisElectronsAuxDyn.pt[signal_el].at(3)\")\n",
    "df = df.Define(\"label\",f'category == \"Higgs\" ? 1 : 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNZSGopUSENX"
   },
   "source": [
    "Specify the columns we'd like to convert to numpy arrays (and put into Pandas data frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZtx_L0jojku"
   },
   "outputs": [],
   "source": [
    "numpy_col = [\"lep1_pt\",\"lep2_pt\",\"lep3_pt\",\"lep4_pt\",\"m4e\",\"label\",\"isData\",\"wgt\",\"category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eBvLGpoSMBp"
   },
   "source": [
    "Import `pandas` and make the conversion from ROOT to Pandas (**not lazy**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "8xF1f4gtof5H",
    "outputId": "f74f0142-abaa-417c-a968-60accc3896d7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pandas_df = pd.DataFrame(data=df.AsNumpy(numpy_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAJdzmslScer"
   },
   "source": [
    "Look at the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "A6-GO-PtEm_P",
    "outputId": "37fc9680-4fbd-4b17-9aa2-6c23701c12c1"
   },
   "outputs": [],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BZu4GWfkrJE"
   },
   "source": [
    "## Machine Learning with RDataFrame\n",
    "\n",
    "It is possible to use the RDataFrames directly in creating PyTorch tensors for machine learning. You already went through a nice tutorial on doing this (if you didn't you should consider doing it). In the following we will do a similar ML tutorial, but instead of using Uproot and awkward arrays we will use directly the RDataFrames and Research Open Data.\n",
    "\n",
    "Not that to be able to do this you need a relatively recent version of ROOT (>= 6.38) and thus it will not work (properly) in Google Colab (root 6.32)\n",
    "\n",
    "In case you haven't run the complete notebook we setup a few things again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT Version: 6.39.01\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "print(f\"ROOT Version: {ROOT.gROOT.GetVersion()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting atlasopenmagic\n",
      "  Using cached atlasopenmagic-1.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pyyaml in /cvmfs/sft-nightlies.cern.ch/lcg/views/devswan/Thu/x86_64-el9-gcc13-opt/lib/python3.13/site-packages (from atlasopenmagic) (6.0.2)\n",
      "Requirement already satisfied: requests in /cvmfs/sft-nightlies.cern.ch/lcg/views/devswan/Thu/x86_64-el9-gcc13-opt/lib/python3.13/site-packages (from atlasopenmagic) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /cvmfs/sft-nightlies.cern.ch/lcg/views/devswan/Thu/x86_64-el9-gcc13-opt/lib/python3.13/site-packages (from atlasopenmagic) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /cvmfs/sft-nightlies.cern.ch/lcg/views/devswan/Thu/x86_64-el9-gcc13-opt/lib/python3.13/site-packages (from requests->atlasopenmagic) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cvmfs/sft-nightlies.cern.ch/lcg/views/devswan/Thu/x86_64-el9-gcc13-opt/lib/python3.13/site-packages (from requests->atlasopenmagic) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cvmfs/sft-nightlies.cern.ch/lcg/views/devswan/Thu/x86_64-el9-gcc13-opt/lib/python3.13/site-packages (from requests->atlasopenmagic) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/sft-nightlies.cern.ch/lcg/views/devswan/Thu/x86_64-el9-gcc13-opt/lib/python3.13/site-packages (from requests->atlasopenmagic) (2024.8.30)\n",
      "Using cached atlasopenmagic-1.8.0-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: atlasopenmagic\n",
      "Successfully installed atlasopenmagic-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# First we install atlasopenmagic into our SWAN environment\n",
    "# Notice that we need --user to avoid trying to install the package in a\n",
    "# read-only file system This is a problem unique to SWAN; on binder or colab you\n",
    "# won't need --user, but it doesn't hurt\n",
    "%pip install --user atlasopenmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to do a little bit of work to make sure that atlasopenmagic is\n",
    "# available in our python path This is because SWAN by default does not include\n",
    "# the local package installation area in the PYTHONPATH Again, this is not\n",
    "# necessary on binder or colab - there you can remove these lines if you like,\n",
    "# though they don't do any harm\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "sys.path += [ f'{os.environ[\"HOME\"]}/.local/lib/python{sys.version_info.major}.{sys.version_info.minor}/site-packages' ]\n",
    "\n",
    "import atlasopenmagic as atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching metadata for release: 2024r-pp...\n",
      "Fetching datasets: 100%|██████████| 374/374 [00:00<00:00, 1152.29datasets/s]\n",
      "✓ Successfully cached 374 datasets.\n",
      "Active release: 2024r-pp. (Datasets path: eos)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"/eos/opendata\"):\n",
    "    atom.set_release('2024r-pp',local_path=\"eos\")\n",
    "else:\n",
    "    atom.set_release('2024r-pp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is done in the ML tutorial on Education and outreach Open Data we'd like to build a supervised classifier that separates fully leptonic $t\\bar{t}$ ($t \\to bW$, $\\bar{t} \\to \\bar{b}W$ (both $W \\to ℓ\\nu$) from Higgs boson events, where $H \\to WW$ and both $W \\to ℓν$. Let's start loading the DSIDs with the simulations of these two processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8fDvjfIIkvHc"
   },
   "outputs": [],
   "source": [
    "MLdefs = {\n",
    "        'ttbar' :{'dids': [411234], 'color': \"#6b59d3\" },\n",
    "        'ggHWW'   :{'dids': [346802],'color': \"#ff0000\" }\n",
    "        }\n",
    "#In swan we can access the samples directly from /eos/ while in colab we must use the root (or https) protocols\n",
    "samples   = atom.build_dataset(MLdefs, cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the json file which will be used to define the RDataFrame (as explained earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4waTKEfnAuv",
    "outputId": "4fbb8d2f-6ee1-4421-d8a2-e7afbc305b37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created json file ./MLspec.json\n",
      "Can now be loaded into a RDataFrame using:\n",
      "df = ROOT.RDF.Experimental.FromSpec(\"./MLspec.json\")\n"
     ]
    }
   ],
   "source": [
    "# Name of the json file.\n",
    "outfilename = \"./MLspec.json\"\n",
    "# Outermost key must be \"samples\"\n",
    "RDF_spec = {\"samples\":{}}\n",
    "# loping over the samples defined above\n",
    "for name, info in MLdefs.items():\n",
    "    for did in info[\"dids\"]:\n",
    "        # Get the metadata from atom\n",
    "        metadata = {'xsec':atom.get_metadata(did,'cross_section_pb'),\n",
    "                    'sumOfWeights':atom.get_metadata(did,'sumOfWeights'),\n",
    "                    'genFiltEff':atom.get_metadata(did,'genFiltEff'),\n",
    "                    'kFactor':atom.get_metadata(did,'kFactor'),\n",
    "                    'proc':name}\n",
    "        # Populates the dictionary with input samples and metadata \n",
    "        RDF_spec['samples'][did] = {\"trees\":[\"CollectionTree\"],\n",
    "                                    \"files\":[item for item in atom.get_urls(str(did), protocol='root', cache=True)[-1:]],\n",
    "                                    \"metadata\":metadata}\n",
    "# Save the dictionary to json file\n",
    "with open(outfilename, \"w\") as f:\n",
    "    json.dump(RDF_spec,f)\n",
    "print(\"Created json file %s\\nCan now be loaded into a RDataFrame using:\\ndf = ROOT.RDF.Experimental.FromSpec(\\\"%s\\\")\"%(outfilename,outfilename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need another C++ function which can take the input from the two containers containing electrons and muons and merge them into one common *lepton* vector. In case you haven't set the paths to the ROOT C++ compiler we do that again (doesn't hurt to do it twice) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ROOTSYS'] = '/content/root_build'\n",
    "os.environ['PATH'] += ':/content/root_build/bin'\n",
    "os.environ['LD_LIBRARY_PATH'] += ':/content/root_build/lib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes as input two vectors and merges the them into a common vector \n",
    "# Returns the joint vector.\n",
    "ROOT.gInterpreter.Declare(\n",
    "    \"\"\"\n",
    "    using VecF_t = const ROOT::RVec<float>&;\n",
    "    ROOT::RVec<float> getVector(VecF_t& inp1, VecF_t& inp2, Float_t m1 = 0 , Float_t m2 = 0){\n",
    "      ROOT::RVec<float> ret_vec;\n",
    "      const auto ninp1 = int(inp1.size());\n",
    "      for (int j=0; j < ninp1; ++j) {\n",
    "        if(m1)ret_vec.push_back(fabs(inp1.at(j))*m1);\n",
    "        else ret_vec.push_back(inp1.at(j));\n",
    "      }\n",
    "  \n",
    "      const auto ninp2 = int(inp2.size());\n",
    "      for (int j=0; j < ninp2; ++j) {\n",
    "        if(m2)ret_vec.push_back(fabs(inp2.at(j))*m2);\n",
    "        else ret_vec.push_back(inp2.at(j));\n",
    "      }\n",
    "  return ret_vec;\n",
    "}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a function to normalize the features we will use in the network. The following takes the mean and standard deviation of each feature and performs standard scaling. It returns the dataframe with the original features replaced by the scaled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeColumns(df, columns, means, stddevs):\n",
    "    for col in columns:\n",
    "        mean = means[col]\n",
    "        std = stddevs[col]\n",
    "        if std == 0:\n",
    "            raise ValueError(f\"Standard deviation of column '{col}' is zero. Cannot normalize.\")\n",
    "        \n",
    "        df = df.Redefine(col, f\"({col} - {mean}) / {std}\")\n",
    "        print(f\"[INFO] Normalized column: {col} \")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "42bFmPAMnSM0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TClass::Init>: no dictionary for class DataHeader_p6 is available\n",
      "Warning in <TClass::Init>: no dictionary for class DataHeaderForm_p6 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::AuxContainerBase is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLinkBase is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::AuxInfoBase is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::EventInfo_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TrigConfKeys_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TrigDecisionAuxInfo_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TrigDecision_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::EventShape_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::Vertex_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class EventStreamInfo_p3 is available\n",
      "Warning in <TClass::Init>: no dictionary for class IOVMetaDataContainer_p1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::FileMetaDataAuxInfo_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class SG::IAuxStore is available\n",
      "Warning in <TClass::Init>: no dictionary for class SG::IConstAuxStore is available\n",
      "Warning in <TClass::Init>: no dictionary for class SG::IAuxStoreIO is available\n",
      "Warning in <TClass::Init>: no dictionary for class SG::IAuxStoreHolder is available\n",
      "Warning in <TClass::Init>: no dictionary for class ILockable is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::CutBookkeeperAuxContainer_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<xAOD::CutBookkeeperContainer_v1> is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TriggerMenuAuxContainer_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::LumiBlockRangeAuxContainer_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class EventType_p3 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::FileMetaData_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class SG::AuxElement is available\n",
      "Warning in <TClass::Init>: no dictionary for class SG::IAuxElement is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::EventFormat_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TriggerMenu_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::LumiBlockRange_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::CutBookkeeper_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class IOVPayloadContainer_p1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class IOVPayloadContainer_p1::CondAttrListCollection_p1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class IOVPayloadContainer_p1::CondAttrListEntry_p1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class IOVPayloadContainer_p1::IOVRange_p1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class AttrListIndexes is available\n",
      "Warning in <TClass::Init>: no dictionary for class DataHeaderForm_p6::DbRecord is available\n",
      "Warning in <TClass::Init>: no dictionary for class Guid is available\n",
      "Warning in <TClass::Init>: no dictionary for class DataHeaderForm_p6::ObjRecord is available\n",
      "Warning in <TClass::Init>: no dictionary for class DataHeader_p6::FullElement is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::MissingETAuxAssociationMap_v2 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::JetAuxContainer_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TauJet_v3 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::IParticle is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::Vertex_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::Jet_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::BTagging_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::Electron_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::Egamma_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TauTrack_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::Muon_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::CaloCluster_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TruthEvent_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TruthEventBase_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TruthVertex_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::Photon_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TrigComposite_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TrackParticle_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TruthParticle_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::TruthVertex_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::TruthParticle_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::TauTrack_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::IParticle> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::Jet_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::CaloCluster_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::TrackParticle_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::MuonSegment_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::Egamma_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::MissingETAssociation_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::MissingET_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::BTagging_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::NeutralParticle_v1> > is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TruthMetaDataAuxContainer_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::TruthMetaData_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class DataVector<xAOD::TriggerMenu_v1> is available\n",
      "Warning in <TClass::Init>: no dictionary for class DataVector<xAOD::LumiBlockRange_v1> is available\n",
      "Warning in <TClass::Init>: no dictionary for class xAOD::CutBookkeeperContainer_v1 is available\n",
      "Warning in <TClass::Init>: no dictionary for class DataVector<xAOD::TruthMetaData_v1> is available\n"
     ]
    }
   ],
   "source": [
    "# Define the RDataFrame and use multi threading\n",
    "#ROOT.EnableImplicitMT(4)\n",
    "df = ROOT.RDF.Experimental.FromSpec(\"MLspec.json\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in df.GetColumnNames():\n",
    "#    if \"AuxDyn\" in col:\n",
    "#        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data set for ML\n",
    "\n",
    "In the next few cells we will prepare the data set to be given to the ML algorithm in PyTorch. We will use basic information about electrons, muons, jets and missing transverse energy as input features. Furthermore, to avoid having varying sized vectors we will convert them into flat variables (e.g. in stead of **lep_pt** we will provide the network with **lep1_pt**, **lep2_pt** for each lepton **1**, **2** etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which samples the events are from (ttbar or ggHWW)\n",
    "df = df.DefinePerSample(\"category\",'rdfsampleinfo_.GetS(\"proc\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XqRH7c2HnVAP"
   },
   "outputs": [],
   "source": [
    "# Define signal objects\n",
    "df = df.Define(\"signal_el\",\"AnalysisElectronsAuxDyn.eta > -2.47 && \\\n",
    "                            AnalysisElectronsAuxDyn.eta <  2.47 && \\\n",
    "                            AnalysisElectronsAuxDyn.pt > 10000 && \\\n",
    "                            AnalysisElectronsAuxDyn.DFCommonElectronsLHLoose\")\n",
    "df = df.Define(\"signal_mu\",\"AnalysisMuonsAuxDyn.eta > -2.47 && \\\n",
    "                            AnalysisMuonsAuxDyn.eta <  2.47 && \\\n",
    "                            AnalysisMuonsAuxDyn.pt > 10000\")\n",
    "df = df.Define(\"signal_jet\",\"AnalysisJetsAuxDyn.eta > -2.5 && \\\n",
    "                            AnalysisJetsAuxDyn.eta <  2.5 && \\\n",
    "                            AnalysisJetsAuxDyn.pt > 20000 && \\\n",
    "                            AnalysisJetsAuxDyn.NNJvtPass\")\n",
    "# This will be our target vector, 1 if events are from ggHWW, 0 otherwise\n",
    "df = df.Define(\"isSignal\",f'category == \"ggHWW\" ? 1 : 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "j1KcwAKsod-M"
   },
   "outputs": [],
   "source": [
    "# Some object multiplicities\n",
    "df = df.Define(\"n_jet\", \"ROOT::VecOps::Sum(signal_jet)\")\n",
    "df = df.Define(\"n_el\", \"ROOT::VecOps::Sum(signal_el)\")\n",
    "df = df.Define(\"n_mu\", \"ROOT::VecOps::Sum(signal_mu)\")\n",
    "df = df.Define(\"n_lep\",\"n_el + n_mu\")\n",
    "# MET variables\n",
    "df = df.Define(\"met_et\",\"MET_TruthAuxDyn.sumet.at(0)/1000.\")\n",
    "df = df.Define(\"met_phi\",\"atan(MET_TruthAuxDyn.mpy.at(0)/MET_TruthAuxDyn.mpx.at(0))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some selections (2 jets and at least two leptons (electrons/muons))\n",
    "df = df.Filter(\"n_jet == 2\",\"Exactly two jets\")\n",
    "df = df.Filter(\"n_lep >= 2\",\"At least two leptons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define the lepton vectors which merges the two sepearete collections of electrons and muons into one\n",
    "# The getVector-function was defined above. \n",
    "df = df.Define('lep_pt',\"getVector(AnalysisElectronsAuxDyn.pt[signal_el],AnalysisMuonsAuxDyn.pt[signal_mu])\")\n",
    "df = df.Define('lep_eta',\"getVector(AnalysisElectronsAuxDyn.eta[signal_el],AnalysisMuonsAuxDyn.eta[signal_mu])\")\n",
    "df = df.Define('lep_phi',\"getVector(AnalysisElectronsAuxDyn.phi[signal_el],AnalysisMuonsAuxDyn.phi[signal_mu])\")\n",
    "# Returns the charge*mass (me = 0.511 MeV, mmu = 105.66 MeV)\n",
    "df = df.Define('lep_mass',\"getVector(AnalysisElectronsAuxDyn.charge[signal_el],AnalysisMuonsAuxDyn.charge[signal_mu],0.511,105.66)\")\n",
    "df = df.Define('lep_charge',\"getVector(AnalysisElectronsAuxDyn.charge[signal_el],AnalysisMuonsAuxDyn.charge[signal_mu])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VoD3klsTqXsH"
   },
   "outputs": [],
   "source": [
    "# Start adding the features we'd like to give to the NN\n",
    "mycolumns = ['met_et','n_el','n_mu','n_lep']#,'met_phi'\n",
    "# Makes flat variables for the first two leptons and jets.\n",
    "# Will always be at least 2 of these since we did the selections above\n",
    "for i in range(1,3):\n",
    "    df = df.Define(\"jet%i_pt\"%i, \"AnalysisJetsAuxDyn.pt[signal_jet].at(%i)/1000.\"%(i-1))\n",
    "    df = df.Define(\"lep%i_pt\"%i, \"lep_pt.at(%i)/1000.\"%(i-1))\n",
    "    \n",
    "    df = df.Define(\"jet%i_eta\"%i, \"AnalysisJetsAuxDyn.eta[signal_jet].at(%i)\"%(i-1))\n",
    "    df = df.Define(\"lep%i_eta\"%i, \"lep_eta.at(%i)\"%(i-1))\n",
    "    \n",
    "    df = df.Define(\"jet%i_phi\"%i, \"AnalysisJetsAuxDyn.phi[signal_jet].at(%i)\"%(i-1))\n",
    "    df = df.Define(\"lep%i_phi\"%i, \"lep_phi.at(%i)\"%(i-1))\n",
    "    \n",
    "    df = df.Define(\"jet%i_mass\"%i, \"AnalysisJetsAuxDyn.m[signal_jet].at(%i)/1000.\"%(i-1))\n",
    "    df = df.Define(\"lep%i_mass\"%i, \"lep_mass.at(%i)/1000.\"%(i-1))\n",
    "    \n",
    "    df = df.Define(\"lep%i_charge\"%i, \"lep_charge.at(%i)\"%(i-1))\n",
    "    \n",
    "    ## And add them to the features\n",
    "    mycolumns.append(\"jet%i_pt\"%i)\n",
    "    mycolumns.append(\"lep%i_pt\"%i)\n",
    "    \n",
    "    mycolumns.append(\"jet%i_eta\"%i)\n",
    "    mycolumns.append(\"lep%i_eta\"%i)\n",
    "    \n",
    "    mycolumns.append(\"jet%i_phi\"%i)\n",
    "    mycolumns.append(\"lep%i_phi\"%i)\n",
    "    \n",
    "    mycolumns.append(\"jet%i_mass\"%i)\n",
    "    mycolumns.append(\"lep%i_mass\"%i)\n",
    "    \n",
    "    mycolumns.append(\"lep%i_charge\"%i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn to the standard scaling of our input features. For every feature we store the mean and standard deviation. This is then used to perform the scaling (in NormalizeColumns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Mean of data met_et: 64.98008803477113\n",
      "[INFO] Mean of data n_el: 1.0385713153096012\n",
      "[INFO] Mean of data n_mu: 0.979703480535955\n",
      "[INFO] Mean of data n_lep: 2.018274795845556\n",
      "[INFO] Mean of data jet1_pt: 56.163044615349115\n",
      "[INFO] Mean of data lep1_pt: 34.34036220101532\n",
      "[INFO] Mean of data jet1_eta: 0.00026733849270640665\n",
      "[INFO] Mean of data lep1_eta: -0.004583949190504022\n",
      "[INFO] Mean of data jet1_phi: 0.023679531517266438\n",
      "[INFO] Mean of data lep1_phi: -0.00327228484220114\n",
      "[INFO] Mean of data jet1_mass: 6.634952459601749\n",
      "[INFO] Mean of data lep1_mass: 0.023678294137525473\n",
      "[INFO] Mean of data lep1_charge: 0.002457781653849203\n",
      "[INFO] Mean of data jet2_pt: 32.52580159065175\n",
      "[INFO] Mean of data lep2_pt: 29.164770692703588\n",
      "[INFO] Mean of data jet2_eta: -0.007599908017821914\n",
      "[INFO] Mean of data lep2_eta: 0.0035200617509335984\n",
      "[INFO] Mean of data jet2_phi: 0.029032605921021994\n",
      "[INFO] Mean of data lep2_phi: -0.005168781019176718\n",
      "[INFO] Mean of data jet2_mass: 4.540291358070039\n",
      "[INFO] Mean of data lep2_mass: 0.0785036665890636\n",
      "[INFO] Mean of data lep2_charge: -0.0022199318163799255\n",
      "[INFO] Stddev of data met_et: 38.92874031183367\n",
      "[INFO] Stddev of data n_el: 0.6921181665008849\n",
      "[INFO] Stddev of data n_mu: 0.7108840427114261\n",
      "[INFO] Stddev of data n_lep: 0.14058850104109769\n",
      "[INFO] Stddev of data jet1_pt: 39.63598294286961\n",
      "[INFO] Stddev of data lep1_pt: 20.41067888284045\n",
      "[INFO] Stddev of data jet1_eta: 1.2416246969450007\n",
      "[INFO] Stddev of data lep1_eta: 1.1591220534440727\n",
      "[INFO] Stddev of data jet1_phi: 1.8111245734047443\n",
      "[INFO] Stddev of data lep1_phi: 1.8122635400599796\n",
      "[INFO] Stddev of data jet1_mass: 5.2414908771448\n",
      "[INFO] Stddev of data lep1_mass: 0.043581758505349656\n",
      "[INFO] Stddev of data lep1_charge: 1.0000168009993455\n",
      "[INFO] Stddev of data jet2_pt: 18.374614548217092\n",
      "[INFO] Stddev of data lep2_pt: 19.98774061491431\n",
      "[INFO] Stddev of data jet2_eta: 1.2967447887838137\n",
      "[INFO] Stddev of data lep2_eta: 1.1847941874723216\n",
      "[INFO] Stddev of data jet2_phi: 1.8137447154453095\n",
      "[INFO] Stddev of data lep2_phi: 1.8157590034261009\n",
      "[INFO] Stddev of data jet2_mass: 2.5607621628162014\n",
      "[INFO] Stddev of data lep2_mass: 0.046022593449907626\n",
      "[INFO] Stddev of data lep2_charge: 1.0000173573085933\n",
      "[INFO] Normalized column: met_et \n",
      "[INFO] Normalized column: n_el \n",
      "[INFO] Normalized column: n_mu \n",
      "[INFO] Normalized column: n_lep \n",
      "[INFO] Normalized column: jet1_pt \n",
      "[INFO] Normalized column: lep1_pt \n",
      "[INFO] Normalized column: jet1_eta \n",
      "[INFO] Normalized column: lep1_eta \n",
      "[INFO] Normalized column: jet1_phi \n",
      "[INFO] Normalized column: lep1_phi \n",
      "[INFO] Normalized column: jet1_mass \n",
      "[INFO] Normalized column: lep1_mass \n",
      "[INFO] Normalized column: lep1_charge \n",
      "[INFO] Normalized column: jet2_pt \n",
      "[INFO] Normalized column: lep2_pt \n",
      "[INFO] Normalized column: jet2_eta \n",
      "[INFO] Normalized column: lep2_eta \n",
      "[INFO] Normalized column: jet2_phi \n",
      "[INFO] Normalized column: lep2_phi \n",
      "[INFO] Normalized column: jet2_mass \n",
      "[INFO] Normalized column: lep2_mass \n",
      "[INFO] Normalized column: lep2_charge \n"
     ]
    }
   ],
   "source": [
    "mean = {col: df.Mean(col) for col in mycolumns}\n",
    "stddev = {col: df.StdDev(col) for col in mycolumns}\n",
    "    \n",
    "ROOT.RDF.RunGraphs(list(mean.values()) + list(stddev.values()))\n",
    "\n",
    "mean_val = {col: mean[col].GetValue() for col in mycolumns}\n",
    "stddev_val = {col: stddev[col].GetValue() for col in mycolumns}\n",
    "\n",
    "for col, val in mean_val.items():\n",
    "    print(f\"[INFO] Mean of data {col}: {val}\")\n",
    "\n",
    "for col, val in stddev_val.items():\n",
    "    print(f\"[INFO] Stddev of data {col}: {val}\")\n",
    "    \n",
    "\n",
    "df = NormalizeColumns(df, mycolumns, mean_val, stddev_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After scaling we add the target vector\n",
    "target = \"isSignal\"  \n",
    "mycolumns.append(\"isSignal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x23f10870>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Snapshot(\"analysis\",\"./MLtrain.root\",mycolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ROOT.RDataFrame(\"analysis\",\"./MLtrain.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FQKBxxaxrJ_O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events : 25226\n"
     ]
    }
   ],
   "source": [
    "# Get the number of events in data set\n",
    "dataset_size = df.Count().GetValue()\n",
    "print(\"Number of events : %i\"%dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "number_of_chunks = 1\n",
    "blocks_per_chunk = 2\n",
    "\n",
    "shuffle = True\n",
    "set_seed = 42\n",
    "batch_size = 1000\n",
    "chunk_size = int(dataset_size / number_of_chunks)\n",
    "block_size = int(chunk_size / blocks_per_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training and validaion sets (as pytorch tensors)\n",
    "gen_train, gen_validation =  ROOT.TMVA.Experimental.CreatePyTorchGenerators(df,\n",
    "                                                                            batch_size,\n",
    "                                                                            chunk_size,\n",
    "                                                                            block_size,\n",
    "                                                                            shuffle = True,\n",
    "                                                                            columns = mycolumns,\n",
    "                                                                            target = target,\n",
    "                                                                            drop_remainder = True,\n",
    "                                                                            set_seed = 42,\n",
    "                                                                            validation_split = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the columns used for training\n",
    "input_columns = gen_train.train_columns\n",
    "Nfeatures = len(input_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just write this as nn.Sequential\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(Nfeatures, 32),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Rprop(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2191799406\n",
      "Epoch [2/20], Loss: 0.1134332055\n",
      "Epoch [3/20], Loss: 0.1098268107\n",
      "Epoch [4/20], Loss: 0.1090076478\n",
      "Epoch [5/20], Loss: 0.1087565093\n",
      "Epoch [6/20], Loss: 0.1086621372\n",
      "Epoch [7/20], Loss: 0.1086071756\n",
      "Epoch [8/20], Loss: 0.1085770713\n",
      "Epoch [9/20], Loss: 0.1085630204\n",
      "Epoch [10/20], Loss: 0.1085543023\n",
      "Epoch [11/20], Loss: 0.1085494003\n",
      "Epoch [12/20], Loss: 0.1085463767\n",
      "Epoch [13/20], Loss: 0.1085440131\n",
      "Epoch [14/20], Loss: 0.1085419458\n",
      "Epoch [15/20], Loss: 0.1085400047\n",
      "Epoch [16/20], Loss: 0.1085381964\n",
      "Epoch [17/20], Loss: 0.1085364718\n",
      "Epoch [18/20], Loss: 0.1085348686\n",
      "Epoch [19/20], Loss: 0.1085333101\n",
      "Epoch [20/20], Loss: 0.1085318156\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses   = []\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    nbatch = 0.\n",
    "    model.train()\n",
    "    for i, (X_train_scaled, Y_train) in enumerate(gen_train):\n",
    "        # tell the optimizer to begin an optimization step\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        # use the model as a prediction function: features → prediction\n",
    "        predictions = model(X_train_scaled)\n",
    "        # compute the loss (χ²) between these predictions and the intended targets\n",
    "        loss = criterion(predictions, Y_train)\n",
    "        # tell the loss function and optimizer to end an optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        nbatch += 1\n",
    "        \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/nbatch:.10f}')\n",
    "    \n",
    "    train_losses.append(running_loss/nbatch)\n",
    "\n",
    "    # add in the validation loss part\n",
    "    for i, (X_val_scaled, Y_val) in enumerate(gen_validation):\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            val_predictions = model(X_val_scaled)\n",
    "            val_loss = criterion(val_predictions, Y_val.reshape(-1,1))\n",
    "            val_losses.append(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2bc7c542d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss function for training and validation sets\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Train Loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the training data set\n",
    "import pandas as pd\n",
    "panda = pd.DataFrame(X_train_scaled.cpu().numpy(),columns=input_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
